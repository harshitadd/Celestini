{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modeltf.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/Celestini/blob/master/Modeltf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdDag8n7lyzH",
        "colab_type": "code",
        "outputId": "1ee3ca50-c59a-4fee-9ec5-5218eaabbfe6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#!pip install joblib\n",
        "import tensorflow as tf \n",
        "import pickle\n",
        "from sklearn.externals import joblib\n",
        "import numpy as np\n",
        "from tensorflow.python.client import device_lib\n",
        "from tensorflow.saved_model import simple_save\n",
        "import random\n",
        "import matplotlib.pyplot as plt \n",
        "import math\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.python import pywrap_tensorflow\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=DeprecationWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO8kr5epl6xf",
        "colab_type": "code",
        "outputId": "0e2b9485-939c-434e-b145-de0c76e2e91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_pKAD2gofS-S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#FEATURES AND LABELS  \n",
        "\n",
        "\n",
        "with open('/content/features_withITO (1).bin','rb') as file:\n",
        "  temp = pickle.load(file)\n",
        "  \n",
        "  \n",
        "with open('/content/labels_withITO (2).bin','rb') as file:\n",
        "  l = pickle.load(file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1yuyj5gdt7r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features =[]\n",
        "for i in temp:\n",
        "  features.append(list(i))\n",
        "\n",
        "labels=[]  \n",
        "for i in l:\n",
        "  labels.append(list(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fDI6dDFEZSCa",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "njR9T1iBZR14",
        "colab": {}
      },
      "source": [
        "## 56 BIT (2253,3147)\n",
        "\n",
        "# features = joblib.load('/content/features56.pkl')\n",
        "# labels = joblib.load('/content/labels56.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "x2E0YxR-ZRno",
        "colab": {}
      },
      "source": [
        "## 64 BIT (2253,3147)\n",
        "\n",
        "# features = joblib.load('/content/features64.pkl')\n",
        "# labels = joblib.load('/content/labels64.pkl')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bnp3GODSODa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # 32 BIT (2253,1035)\n",
        "\n",
        "# features = joblib.load('/content/features32.pkl')\n",
        "# labels = joblib.load('/content/labels32.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ufRdxblS8OC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6Zxm0XF0DlH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TEST SET \n",
        "\n",
        "x_train_t, x_test_t,y_train_t, y_test_t = train_test_split(features, labels, test_size = 0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAlnu945gPXq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkXJ4fuuhWgh",
        "colab_type": "code",
        "outputId": "fab7226f-0909-41ba-c9bc-a2733227c04d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        }
      },
      "source": [
        "print(device_lib.list_local_devices())\n"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 5920626892490842763\n",
            ", name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 694842427357957988\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            ", name: \"/device:XLA_GPU:0\"\n",
            "device_type: \"XLA_GPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 8753849175344013415\n",
            "physical_device_desc: \"device: XLA_GPU device\"\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14892338381\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 3004212435850716996\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OOY3qbW1EcN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from keras.layers import Dense, Dropout, BatchNormalization\n",
        "from keras.models import Sequential\n",
        "from keras.optimizers import Adam\n",
        "model = Sequential()\n",
        "model.add(Dense(15, input_shape = (9, ), activation = 'relu'))\n",
        "model.add(Dense(25, activation = 'relu'))\n",
        "model.add(Dense(1,  activation = 'relu'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJUpMCEi1gGb",
        "colab_type": "code",
        "outputId": "d4650bc9-7c9b-4789-c609-32a3212f2cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "model.compile(optimizer = Adam(lr = 0.001),loss='mse')\n",
        "model.summary()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 15)                150       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 25)                400       \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 26        \n",
            "=================================================================\n",
            "Total params: 576\n",
            "Trainable params: 576\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSUO_k7P110C",
        "colab_type": "code",
        "outputId": "82ae8d4e-50cf-4e36-f400-97f9adf5b5ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "hist = model.fit([x_train_t], [y_train_t], validation_split = 0.33, epochs = 1000, verbose = 1, batch_size = 32, shuffle = True)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0806 16:02:14.911203 140530293823360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "W0806 16:02:14.993621 140530293823360 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1114 samples, validate on 549 samples\n",
            "Epoch 1/1000\n",
            "1114/1114 [==============================] - 0s 341us/step - loss: 3136.5414 - val_loss: 3623.1212\n",
            "Epoch 2/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 3008.6712 - val_loss: 3427.6719\n",
            "Epoch 3/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 2736.1665 - val_loss: 3023.6587\n",
            "Epoch 4/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 2248.5157 - val_loss: 2391.2061\n",
            "Epoch 5/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 1620.1925 - val_loss: 1677.6857\n",
            "Epoch 6/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 1052.4504 - val_loss: 1163.6728\n",
            "Epoch 7/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 759.6254 - val_loss: 966.9229\n",
            "Epoch 8/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 691.4833 - val_loss: 920.4528\n",
            "Epoch 9/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 681.7568 - val_loss: 912.4736\n",
            "Epoch 10/1000\n",
            "1114/1114 [==============================] - 0s 116us/step - loss: 676.1345 - val_loss: 903.7167\n",
            "Epoch 11/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 670.4226 - val_loss: 895.3779\n",
            "Epoch 12/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 664.7323 - val_loss: 890.2936\n",
            "Epoch 13/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 659.6026 - val_loss: 883.6841\n",
            "Epoch 14/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 654.8856 - val_loss: 877.6449\n",
            "Epoch 15/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 649.6403 - val_loss: 870.0355\n",
            "Epoch 16/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 645.1599 - val_loss: 861.1999\n",
            "Epoch 17/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 640.7173 - val_loss: 858.2766\n",
            "Epoch 18/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 635.9874 - val_loss: 850.1837\n",
            "Epoch 19/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 631.8311 - val_loss: 847.8543\n",
            "Epoch 20/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 627.7707 - val_loss: 839.5969\n",
            "Epoch 21/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 623.8969 - val_loss: 834.9092\n",
            "Epoch 22/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 620.6921 - val_loss: 830.1397\n",
            "Epoch 23/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 617.1828 - val_loss: 825.7206\n",
            "Epoch 24/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 613.8462 - val_loss: 820.0375\n",
            "Epoch 25/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 610.7670 - val_loss: 816.3362\n",
            "Epoch 26/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 607.1451 - val_loss: 814.6192\n",
            "Epoch 27/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 606.0167 - val_loss: 812.7685\n",
            "Epoch 28/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 601.7224 - val_loss: 802.2747\n",
            "Epoch 29/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 599.3376 - val_loss: 800.4664\n",
            "Epoch 30/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 596.7939 - val_loss: 796.9225\n",
            "Epoch 31/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 595.2343 - val_loss: 793.6384\n",
            "Epoch 32/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 592.0856 - val_loss: 792.5128\n",
            "Epoch 33/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 590.9123 - val_loss: 786.4175\n",
            "Epoch 34/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 588.3582 - val_loss: 784.5995\n",
            "Epoch 35/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 586.0420 - val_loss: 783.4795\n",
            "Epoch 36/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 583.7792 - val_loss: 777.7951\n",
            "Epoch 37/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 582.2615 - val_loss: 776.4602\n",
            "Epoch 38/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 580.5052 - val_loss: 774.5101\n",
            "Epoch 39/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 578.8703 - val_loss: 772.3589\n",
            "Epoch 40/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 577.2546 - val_loss: 769.6420\n",
            "Epoch 41/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 575.3370 - val_loss: 767.1818\n",
            "Epoch 42/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 574.1600 - val_loss: 764.9552\n",
            "Epoch 43/1000\n",
            "1114/1114 [==============================] - 0s 116us/step - loss: 572.6343 - val_loss: 762.4312\n",
            "Epoch 44/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 570.6783 - val_loss: 756.4881\n",
            "Epoch 45/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 570.2812 - val_loss: 755.5518\n",
            "Epoch 46/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 568.6133 - val_loss: 756.5253\n",
            "Epoch 47/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 566.0955 - val_loss: 756.5707\n",
            "Epoch 48/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 564.8162 - val_loss: 748.2618\n",
            "Epoch 49/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 564.4258 - val_loss: 755.1789\n",
            "Epoch 50/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 562.0629 - val_loss: 749.3404\n",
            "Epoch 51/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 560.0605 - val_loss: 745.3713\n",
            "Epoch 52/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 559.4658 - val_loss: 742.1180\n",
            "Epoch 53/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 557.9612 - val_loss: 742.1988\n",
            "Epoch 54/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 556.2841 - val_loss: 742.9741\n",
            "Epoch 55/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 556.1725 - val_loss: 745.6640\n",
            "Epoch 56/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 554.5322 - val_loss: 740.1869\n",
            "Epoch 57/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 552.6386 - val_loss: 734.3962\n",
            "Epoch 58/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 550.9065 - val_loss: 736.5596\n",
            "Epoch 59/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 550.1373 - val_loss: 736.7510\n",
            "Epoch 60/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 549.2932 - val_loss: 729.3622\n",
            "Epoch 61/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 547.3013 - val_loss: 729.7168\n",
            "Epoch 62/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 545.9990 - val_loss: 732.2260\n",
            "Epoch 63/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 544.8975 - val_loss: 724.7017\n",
            "Epoch 64/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 543.4721 - val_loss: 725.6078\n",
            "Epoch 65/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 542.9494 - val_loss: 722.8942\n",
            "Epoch 66/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 540.8744 - val_loss: 723.7757\n",
            "Epoch 67/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 540.3298 - val_loss: 727.5816\n",
            "Epoch 68/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 538.9559 - val_loss: 720.8701\n",
            "Epoch 69/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 537.7271 - val_loss: 720.6051\n",
            "Epoch 70/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 536.6748 - val_loss: 717.3113\n",
            "Epoch 71/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 536.1568 - val_loss: 718.5542\n",
            "Epoch 72/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 534.6152 - val_loss: 719.3183\n",
            "Epoch 73/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 533.7811 - val_loss: 715.1353\n",
            "Epoch 74/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 532.4932 - val_loss: 715.4705\n",
            "Epoch 75/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 531.6419 - val_loss: 715.9187\n",
            "Epoch 76/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 531.4947 - val_loss: 711.8266\n",
            "Epoch 77/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 530.8634 - val_loss: 713.3549\n",
            "Epoch 78/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 529.8860 - val_loss: 709.6569\n",
            "Epoch 79/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 527.9630 - val_loss: 711.6847\n",
            "Epoch 80/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 527.6542 - val_loss: 713.0052\n",
            "Epoch 81/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 527.4424 - val_loss: 706.1763\n",
            "Epoch 82/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 526.7308 - val_loss: 705.8305\n",
            "Epoch 83/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 525.0696 - val_loss: 707.7136\n",
            "Epoch 84/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 524.8355 - val_loss: 704.6934\n",
            "Epoch 85/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 523.3468 - val_loss: 707.9430\n",
            "Epoch 86/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 522.9247 - val_loss: 709.4421\n",
            "Epoch 87/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 522.0983 - val_loss: 706.0696\n",
            "Epoch 88/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 521.4042 - val_loss: 703.2675\n",
            "Epoch 89/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 520.8074 - val_loss: 704.8303\n",
            "Epoch 90/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 520.4113 - val_loss: 700.2457\n",
            "Epoch 91/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 520.5623 - val_loss: 701.5499\n",
            "Epoch 92/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 519.6600 - val_loss: 704.9108\n",
            "Epoch 93/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 518.1826 - val_loss: 700.1870\n",
            "Epoch 94/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 518.2734 - val_loss: 696.4311\n",
            "Epoch 95/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 516.8422 - val_loss: 703.6446\n",
            "Epoch 96/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 517.7824 - val_loss: 695.4563\n",
            "Epoch 97/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 516.0338 - val_loss: 697.4700\n",
            "Epoch 98/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 515.8497 - val_loss: 696.5894\n",
            "Epoch 99/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 515.3556 - val_loss: 698.4984\n",
            "Epoch 100/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 516.3064 - val_loss: 702.4102\n",
            "Epoch 101/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 514.2868 - val_loss: 694.9751\n",
            "Epoch 102/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 513.7687 - val_loss: 695.8228\n",
            "Epoch 103/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 513.4606 - val_loss: 690.3063\n",
            "Epoch 104/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 512.9166 - val_loss: 698.4290\n",
            "Epoch 105/1000\n",
            "1114/1114 [==============================] - 0s 108us/step - loss: 514.8175 - val_loss: 690.4023\n",
            "Epoch 106/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 512.0696 - val_loss: 693.3929\n",
            "Epoch 107/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 511.4512 - val_loss: 695.3031\n",
            "Epoch 108/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 512.2288 - val_loss: 692.5067\n",
            "Epoch 109/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 511.7650 - val_loss: 694.1245\n",
            "Epoch 110/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 511.4160 - val_loss: 694.3576\n",
            "Epoch 111/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 510.8291 - val_loss: 692.0659\n",
            "Epoch 112/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 510.4683 - val_loss: 687.9431\n",
            "Epoch 113/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 509.1369 - val_loss: 692.1471\n",
            "Epoch 114/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 508.7500 - val_loss: 688.7333\n",
            "Epoch 115/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 508.9498 - val_loss: 688.9301\n",
            "Epoch 116/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 508.5325 - val_loss: 687.2471\n",
            "Epoch 117/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 508.4397 - val_loss: 686.1665\n",
            "Epoch 118/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 508.8957 - val_loss: 687.5124\n",
            "Epoch 119/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 508.5859 - val_loss: 688.1578\n",
            "Epoch 120/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 508.6824 - val_loss: 686.6861\n",
            "Epoch 121/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 507.3917 - val_loss: 685.9732\n",
            "Epoch 122/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 507.4833 - val_loss: 686.5146\n",
            "Epoch 123/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 506.2085 - val_loss: 683.8921\n",
            "Epoch 124/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 505.3857 - val_loss: 684.9357\n",
            "Epoch 125/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 503.8871 - val_loss: 682.1729\n",
            "Epoch 126/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 504.4161 - val_loss: 682.5459\n",
            "Epoch 127/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 502.5665 - val_loss: 678.8460\n",
            "Epoch 128/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 501.2374 - val_loss: 679.5025\n",
            "Epoch 129/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 500.2604 - val_loss: 679.6293\n",
            "Epoch 130/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 498.9188 - val_loss: 676.9543\n",
            "Epoch 131/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 497.5342 - val_loss: 674.9380\n",
            "Epoch 132/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 497.2356 - val_loss: 675.7399\n",
            "Epoch 133/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 496.1784 - val_loss: 669.1851\n",
            "Epoch 134/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 495.9267 - val_loss: 665.2844\n",
            "Epoch 135/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 493.9513 - val_loss: 669.5082\n",
            "Epoch 136/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 494.7305 - val_loss: 672.2981\n",
            "Epoch 137/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 491.3895 - val_loss: 666.0235\n",
            "Epoch 138/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 490.5039 - val_loss: 663.7264\n",
            "Epoch 139/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 490.0966 - val_loss: 663.8951\n",
            "Epoch 140/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 489.3591 - val_loss: 662.9968\n",
            "Epoch 141/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 487.6472 - val_loss: 660.0583\n",
            "Epoch 142/1000\n",
            "1114/1114 [==============================] - 0s 115us/step - loss: 486.9396 - val_loss: 659.9536\n",
            "Epoch 143/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 486.2615 - val_loss: 656.9852\n",
            "Epoch 144/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 486.4082 - val_loss: 658.0551\n",
            "Epoch 145/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 484.6754 - val_loss: 652.5163\n",
            "Epoch 146/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 485.6958 - val_loss: 650.4075\n",
            "Epoch 147/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 483.6580 - val_loss: 656.6617\n",
            "Epoch 148/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 482.3536 - val_loss: 651.7407\n",
            "Epoch 149/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 482.4426 - val_loss: 654.6288\n",
            "Epoch 150/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 481.5062 - val_loss: 650.5756\n",
            "Epoch 151/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 480.1033 - val_loss: 648.5010\n",
            "Epoch 152/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 480.8998 - val_loss: 646.6095\n",
            "Epoch 153/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 478.5265 - val_loss: 642.7405\n",
            "Epoch 154/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 477.7033 - val_loss: 641.6564\n",
            "Epoch 155/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 476.1656 - val_loss: 647.3394\n",
            "Epoch 156/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 475.4896 - val_loss: 641.8659\n",
            "Epoch 157/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 474.0718 - val_loss: 639.0111\n",
            "Epoch 158/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 472.4522 - val_loss: 638.7103\n",
            "Epoch 159/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 471.7658 - val_loss: 637.3122\n",
            "Epoch 160/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 471.5513 - val_loss: 637.1450\n",
            "Epoch 161/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 470.1557 - val_loss: 631.7501\n",
            "Epoch 162/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 468.7761 - val_loss: 631.0460\n",
            "Epoch 163/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 468.8165 - val_loss: 631.8469\n",
            "Epoch 164/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 466.9045 - val_loss: 629.7189\n",
            "Epoch 165/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 467.5731 - val_loss: 623.5202\n",
            "Epoch 166/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 464.5793 - val_loss: 625.3355\n",
            "Epoch 167/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 462.8149 - val_loss: 625.3752\n",
            "Epoch 168/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 462.1570 - val_loss: 623.1292\n",
            "Epoch 169/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 460.7897 - val_loss: 620.3321\n",
            "Epoch 170/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 459.2274 - val_loss: 617.8627\n",
            "Epoch 171/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 458.5164 - val_loss: 616.7740\n",
            "Epoch 172/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 456.3452 - val_loss: 617.8199\n",
            "Epoch 173/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 456.3461 - val_loss: 613.2475\n",
            "Epoch 174/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 453.8271 - val_loss: 615.1174\n",
            "Epoch 175/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 452.9749 - val_loss: 608.6731\n",
            "Epoch 176/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 451.6720 - val_loss: 612.1783\n",
            "Epoch 177/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 450.4251 - val_loss: 608.3857\n",
            "Epoch 178/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 449.0464 - val_loss: 607.1410\n",
            "Epoch 179/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 447.6570 - val_loss: 600.2743\n",
            "Epoch 180/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 446.0090 - val_loss: 602.4613\n",
            "Epoch 181/1000\n",
            "1114/1114 [==============================] - 0s 222us/step - loss: 444.4766 - val_loss: 598.5603\n",
            "Epoch 182/1000\n",
            " 672/1114 [=================>............] - ETA: 0s - loss: 470.5375"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:122: UserWarning: Method on_batch_end() is slow compared to the batch update (0.134917). Check your callbacks.\n",
            "  % delta_t_median)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1114/1114 [==============================] - 0s 97us/step - loss: 442.8164 - val_loss: 597.1695\n",
            "Epoch 183/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 441.2712 - val_loss: 592.9066\n",
            "Epoch 184/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 440.9495 - val_loss: 589.1887\n",
            "Epoch 185/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 438.1663 - val_loss: 590.8859\n",
            "Epoch 186/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 437.3034 - val_loss: 590.7310\n",
            "Epoch 187/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 435.5905 - val_loss: 583.6838\n",
            "Epoch 188/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 433.7770 - val_loss: 588.0769\n",
            "Epoch 189/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 433.2048 - val_loss: 584.9865\n",
            "Epoch 190/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 431.0554 - val_loss: 580.6940\n",
            "Epoch 191/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 429.6295 - val_loss: 579.8286\n",
            "Epoch 192/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 428.3327 - val_loss: 580.8714\n",
            "Epoch 193/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 426.2888 - val_loss: 573.8883\n",
            "Epoch 194/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 426.2095 - val_loss: 571.5101\n",
            "Epoch 195/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 423.8994 - val_loss: 568.5750\n",
            "Epoch 196/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 423.0196 - val_loss: 567.9002\n",
            "Epoch 197/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 420.9395 - val_loss: 571.2420\n",
            "Epoch 198/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 419.5841 - val_loss: 565.9960\n",
            "Epoch 199/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 419.9594 - val_loss: 564.9490\n",
            "Epoch 200/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 417.9013 - val_loss: 564.6656\n",
            "Epoch 201/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 416.0292 - val_loss: 560.5709\n",
            "Epoch 202/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 415.2013 - val_loss: 564.6113\n",
            "Epoch 203/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 413.5947 - val_loss: 553.1075\n",
            "Epoch 204/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 411.8533 - val_loss: 561.2621\n",
            "Epoch 205/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 410.5738 - val_loss: 555.1211\n",
            "Epoch 206/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 409.0589 - val_loss: 552.2766\n",
            "Epoch 207/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 407.4553 - val_loss: 554.5200\n",
            "Epoch 208/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 406.8363 - val_loss: 551.6626\n",
            "Epoch 209/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 406.7601 - val_loss: 549.6208\n",
            "Epoch 210/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 404.1073 - val_loss: 545.3071\n",
            "Epoch 211/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 404.2213 - val_loss: 543.6830\n",
            "Epoch 212/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 402.1693 - val_loss: 545.5019\n",
            "Epoch 213/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 403.3258 - val_loss: 546.6308\n",
            "Epoch 214/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 401.1897 - val_loss: 541.6510\n",
            "Epoch 215/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 398.6142 - val_loss: 539.9444\n",
            "Epoch 216/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 397.5831 - val_loss: 538.1243\n",
            "Epoch 217/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 396.9024 - val_loss: 538.4432\n",
            "Epoch 218/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 396.1398 - val_loss: 536.2305\n",
            "Epoch 219/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 395.4269 - val_loss: 539.1283\n",
            "Epoch 220/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 394.5514 - val_loss: 535.3978\n",
            "Epoch 221/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 393.4289 - val_loss: 529.6241\n",
            "Epoch 222/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 391.7915 - val_loss: 528.8946\n",
            "Epoch 223/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 390.8901 - val_loss: 531.7639\n",
            "Epoch 224/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 390.2174 - val_loss: 527.5807\n",
            "Epoch 225/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 388.3547 - val_loss: 525.3449\n",
            "Epoch 226/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 386.8973 - val_loss: 525.3816\n",
            "Epoch 227/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 385.9359 - val_loss: 525.4679\n",
            "Epoch 228/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 384.7773 - val_loss: 523.5735\n",
            "Epoch 229/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 384.3113 - val_loss: 524.2055\n",
            "Epoch 230/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 385.0479 - val_loss: 516.2201\n",
            "Epoch 231/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 382.7277 - val_loss: 519.5546\n",
            "Epoch 232/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 383.2887 - val_loss: 522.4407\n",
            "Epoch 233/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 378.7474 - val_loss: 515.1537\n",
            "Epoch 234/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 378.7990 - val_loss: 515.2936\n",
            "Epoch 235/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 377.5431 - val_loss: 514.6915\n",
            "Epoch 236/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 377.4838 - val_loss: 510.9621\n",
            "Epoch 237/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 376.9762 - val_loss: 514.6346\n",
            "Epoch 238/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 374.5239 - val_loss: 512.9551\n",
            "Epoch 239/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 373.8524 - val_loss: 508.2074\n",
            "Epoch 240/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 372.8052 - val_loss: 506.1672\n",
            "Epoch 241/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 372.0695 - val_loss: 508.2982\n",
            "Epoch 242/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 371.7135 - val_loss: 504.3697\n",
            "Epoch 243/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 370.7425 - val_loss: 503.3610\n",
            "Epoch 244/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 369.6040 - val_loss: 503.6950\n",
            "Epoch 245/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 368.3884 - val_loss: 503.9452\n",
            "Epoch 246/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 367.9366 - val_loss: 505.4655\n",
            "Epoch 247/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 367.0939 - val_loss: 498.5963\n",
            "Epoch 248/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 365.5167 - val_loss: 500.5508\n",
            "Epoch 249/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 365.2185 - val_loss: 497.6260\n",
            "Epoch 250/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 364.2703 - val_loss: 499.2401\n",
            "Epoch 251/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 362.8879 - val_loss: 496.8578\n",
            "Epoch 252/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 362.7625 - val_loss: 493.1200\n",
            "Epoch 253/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 361.6721 - val_loss: 493.9132\n",
            "Epoch 254/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 360.8220 - val_loss: 495.8223\n",
            "Epoch 255/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 360.5413 - val_loss: 493.3969\n",
            "Epoch 256/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 360.2192 - val_loss: 491.3124\n",
            "Epoch 257/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 358.7301 - val_loss: 492.5308\n",
            "Epoch 258/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 359.1438 - val_loss: 493.0135\n",
            "Epoch 259/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 359.2103 - val_loss: 487.3944\n",
            "Epoch 260/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 357.9439 - val_loss: 487.9322\n",
            "Epoch 261/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 356.7190 - val_loss: 486.4726\n",
            "Epoch 262/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 355.7728 - val_loss: 485.7107\n",
            "Epoch 263/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 355.1228 - val_loss: 487.0826\n",
            "Epoch 264/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 354.9515 - val_loss: 484.9482\n",
            "Epoch 265/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 354.3304 - val_loss: 488.1696\n",
            "Epoch 266/1000\n",
            "1114/1114 [==============================] - 0s 107us/step - loss: 353.4697 - val_loss: 486.8840\n",
            "Epoch 267/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 352.9341 - val_loss: 485.5380\n",
            "Epoch 268/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 352.9937 - val_loss: 486.9141\n",
            "Epoch 269/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 352.7087 - val_loss: 483.3242\n",
            "Epoch 270/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 351.9805 - val_loss: 481.1211\n",
            "Epoch 271/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 352.1253 - val_loss: 489.5189\n",
            "Epoch 272/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 350.2298 - val_loss: 479.2844\n",
            "Epoch 273/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 349.6818 - val_loss: 484.6767\n",
            "Epoch 274/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 351.4973 - val_loss: 479.6644\n",
            "Epoch 275/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 351.1080 - val_loss: 479.8124\n",
            "Epoch 276/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 349.4674 - val_loss: 484.6553\n",
            "Epoch 277/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 348.9929 - val_loss: 485.1252\n",
            "Epoch 278/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 349.1699 - val_loss: 482.4260\n",
            "Epoch 279/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 347.6461 - val_loss: 476.6091\n",
            "Epoch 280/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 346.4976 - val_loss: 480.2544\n",
            "Epoch 281/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 346.2153 - val_loss: 480.7681\n",
            "Epoch 282/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 346.0065 - val_loss: 476.2698\n",
            "Epoch 283/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 345.2714 - val_loss: 474.7596\n",
            "Epoch 284/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 345.5857 - val_loss: 477.7539\n",
            "Epoch 285/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 345.1722 - val_loss: 472.2249\n",
            "Epoch 286/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 344.8376 - val_loss: 474.9626\n",
            "Epoch 287/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 343.1715 - val_loss: 474.3782\n",
            "Epoch 288/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 341.7981 - val_loss: 473.3166\n",
            "Epoch 289/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 341.9499 - val_loss: 470.7345\n",
            "Epoch 290/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 342.4556 - val_loss: 476.0155\n",
            "Epoch 291/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 340.8107 - val_loss: 471.4514\n",
            "Epoch 292/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 340.2515 - val_loss: 468.3036\n",
            "Epoch 293/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 339.3468 - val_loss: 468.9061\n",
            "Epoch 294/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 338.3009 - val_loss: 470.5855\n",
            "Epoch 295/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 339.2733 - val_loss: 473.4456\n",
            "Epoch 296/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 338.1306 - val_loss: 470.3287\n",
            "Epoch 297/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 337.5456 - val_loss: 471.2969\n",
            "Epoch 298/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 337.2744 - val_loss: 469.2528\n",
            "Epoch 299/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 337.0545 - val_loss: 468.8166\n",
            "Epoch 300/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 336.9320 - val_loss: 467.1608\n",
            "Epoch 301/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 336.5854 - val_loss: 468.2767\n",
            "Epoch 302/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 335.9806 - val_loss: 470.0500\n",
            "Epoch 303/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 335.3536 - val_loss: 468.2786\n",
            "Epoch 304/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 335.7055 - val_loss: 470.2836\n",
            "Epoch 305/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 335.8248 - val_loss: 467.9872\n",
            "Epoch 306/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 336.6157 - val_loss: 467.5893\n",
            "Epoch 307/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 334.8049 - val_loss: 469.7023\n",
            "Epoch 308/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 334.3864 - val_loss: 466.7230\n",
            "Epoch 309/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 333.6207 - val_loss: 463.8901\n",
            "Epoch 310/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 333.0857 - val_loss: 463.5837\n",
            "Epoch 311/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 332.5542 - val_loss: 463.5502\n",
            "Epoch 312/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 333.1124 - val_loss: 460.4963\n",
            "Epoch 313/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 334.7383 - val_loss: 460.2178\n",
            "Epoch 314/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 333.7086 - val_loss: 464.9934\n",
            "Epoch 315/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 332.6659 - val_loss: 464.6643\n",
            "Epoch 316/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 331.8409 - val_loss: 464.7853\n",
            "Epoch 317/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 330.5278 - val_loss: 461.9595\n",
            "Epoch 318/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 331.4367 - val_loss: 461.1335\n",
            "Epoch 319/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 329.8822 - val_loss: 465.7705\n",
            "Epoch 320/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 330.6883 - val_loss: 461.3903\n",
            "Epoch 321/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 329.9069 - val_loss: 463.6373\n",
            "Epoch 322/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 331.0428 - val_loss: 467.1637\n",
            "Epoch 323/1000\n",
            "1114/1114 [==============================] - 0s 110us/step - loss: 329.4612 - val_loss: 463.0215\n",
            "Epoch 324/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 329.3132 - val_loss: 458.1523\n",
            "Epoch 325/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 330.1836 - val_loss: 466.0959\n",
            "Epoch 326/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 330.4861 - val_loss: 463.5435\n",
            "Epoch 327/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 328.3415 - val_loss: 462.5938\n",
            "Epoch 328/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 328.6471 - val_loss: 457.7622\n",
            "Epoch 329/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 329.1399 - val_loss: 456.1943\n",
            "Epoch 330/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 327.4194 - val_loss: 460.3730\n",
            "Epoch 331/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 326.5160 - val_loss: 458.2586\n",
            "Epoch 332/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 326.2788 - val_loss: 457.9218\n",
            "Epoch 333/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 325.9824 - val_loss: 458.5443\n",
            "Epoch 334/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 326.5431 - val_loss: 460.4109\n",
            "Epoch 335/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 325.7594 - val_loss: 456.0717\n",
            "Epoch 336/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 327.2424 - val_loss: 462.6296\n",
            "Epoch 337/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 326.4287 - val_loss: 459.9752\n",
            "Epoch 338/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 325.9839 - val_loss: 461.7814\n",
            "Epoch 339/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 325.5953 - val_loss: 454.4204\n",
            "Epoch 340/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 325.0310 - val_loss: 457.0492\n",
            "Epoch 341/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 323.8044 - val_loss: 454.7848\n",
            "Epoch 342/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 323.4141 - val_loss: 456.2579\n",
            "Epoch 343/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 323.7232 - val_loss: 456.5960\n",
            "Epoch 344/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 323.1784 - val_loss: 454.7723\n",
            "Epoch 345/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 322.6825 - val_loss: 454.8204\n",
            "Epoch 346/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 322.6325 - val_loss: 458.1004\n",
            "Epoch 347/1000\n",
            "1114/1114 [==============================] - 0s 108us/step - loss: 323.7419 - val_loss: 456.2384\n",
            "Epoch 348/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 322.2911 - val_loss: 455.1977\n",
            "Epoch 349/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 321.2642 - val_loss: 454.3621\n",
            "Epoch 350/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 322.3230 - val_loss: 453.1312\n",
            "Epoch 351/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 320.9725 - val_loss: 451.4804\n",
            "Epoch 352/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 321.7326 - val_loss: 453.2234\n",
            "Epoch 353/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 321.0263 - val_loss: 451.3870\n",
            "Epoch 354/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 322.0249 - val_loss: 449.8937\n",
            "Epoch 355/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 320.9609 - val_loss: 449.5808\n",
            "Epoch 356/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 321.1595 - val_loss: 450.7819\n",
            "Epoch 357/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 320.1062 - val_loss: 454.0745\n",
            "Epoch 358/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 318.8212 - val_loss: 451.0455\n",
            "Epoch 359/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 318.9668 - val_loss: 459.1384\n",
            "Epoch 360/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 320.1941 - val_loss: 448.7344\n",
            "Epoch 361/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 319.3427 - val_loss: 457.0797\n",
            "Epoch 362/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 319.7706 - val_loss: 450.5119\n",
            "Epoch 363/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 319.6230 - val_loss: 446.7064\n",
            "Epoch 364/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 318.7632 - val_loss: 447.3813\n",
            "Epoch 365/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 317.9693 - val_loss: 448.0363\n",
            "Epoch 366/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 317.2816 - val_loss: 450.1731\n",
            "Epoch 367/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 318.3136 - val_loss: 452.5384\n",
            "Epoch 368/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 316.9388 - val_loss: 447.4036\n",
            "Epoch 369/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 316.8282 - val_loss: 451.9138\n",
            "Epoch 370/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 316.5274 - val_loss: 448.8306\n",
            "Epoch 371/1000\n",
            "1114/1114 [==============================] - 0s 108us/step - loss: 316.3109 - val_loss: 446.6084\n",
            "Epoch 372/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 317.2816 - val_loss: 446.8880\n",
            "Epoch 373/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 316.2205 - val_loss: 451.6958\n",
            "Epoch 374/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 316.5604 - val_loss: 445.1966\n",
            "Epoch 375/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 316.8610 - val_loss: 446.3461\n",
            "Epoch 376/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 315.6674 - val_loss: 448.4176\n",
            "Epoch 377/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 316.2890 - val_loss: 445.0360\n",
            "Epoch 378/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 317.3909 - val_loss: 445.5477\n",
            "Epoch 379/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 316.8628 - val_loss: 450.8320\n",
            "Epoch 380/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 315.0229 - val_loss: 451.2289\n",
            "Epoch 381/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 316.1868 - val_loss: 452.6781\n",
            "Epoch 382/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 315.0845 - val_loss: 447.7263\n",
            "Epoch 383/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 315.6256 - val_loss: 449.1444\n",
            "Epoch 384/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 313.3520 - val_loss: 443.7670\n",
            "Epoch 385/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 313.7382 - val_loss: 444.2032\n",
            "Epoch 386/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 313.6277 - val_loss: 449.7287\n",
            "Epoch 387/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 312.9234 - val_loss: 445.2621\n",
            "Epoch 388/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 313.3855 - val_loss: 449.0988\n",
            "Epoch 389/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 313.0458 - val_loss: 443.3772\n",
            "Epoch 390/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 312.6776 - val_loss: 447.8905\n",
            "Epoch 391/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 313.0352 - val_loss: 441.5067\n",
            "Epoch 392/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 311.3955 - val_loss: 445.5484\n",
            "Epoch 393/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 311.2252 - val_loss: 444.7079\n",
            "Epoch 394/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 311.8204 - val_loss: 445.0216\n",
            "Epoch 395/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 310.8845 - val_loss: 443.4208\n",
            "Epoch 396/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 311.5388 - val_loss: 441.8775\n",
            "Epoch 397/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 311.1880 - val_loss: 441.7383\n",
            "Epoch 398/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 310.5004 - val_loss: 442.6198\n",
            "Epoch 399/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 311.6012 - val_loss: 443.5762\n",
            "Epoch 400/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 309.9862 - val_loss: 441.9916\n",
            "Epoch 401/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 310.1293 - val_loss: 438.6816\n",
            "Epoch 402/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 311.3898 - val_loss: 439.3376\n",
            "Epoch 403/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 310.3340 - val_loss: 443.5093\n",
            "Epoch 404/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 310.3995 - val_loss: 444.4395\n",
            "Epoch 405/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 309.3546 - val_loss: 440.6131\n",
            "Epoch 406/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 309.7031 - val_loss: 438.6534\n",
            "Epoch 407/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 309.4643 - val_loss: 440.5225\n",
            "Epoch 408/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 308.7858 - val_loss: 440.8020\n",
            "Epoch 409/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 309.0448 - val_loss: 440.5190\n",
            "Epoch 410/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 310.2177 - val_loss: 441.2038\n",
            "Epoch 411/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 309.8227 - val_loss: 439.2880\n",
            "Epoch 412/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 308.5384 - val_loss: 438.4151\n",
            "Epoch 413/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 308.2691 - val_loss: 442.2267\n",
            "Epoch 414/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 310.6761 - val_loss: 441.5675\n",
            "Epoch 415/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 309.4606 - val_loss: 438.3345\n",
            "Epoch 416/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 307.3629 - val_loss: 436.6356\n",
            "Epoch 417/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 307.0986 - val_loss: 437.4137\n",
            "Epoch 418/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 306.8502 - val_loss: 438.2428\n",
            "Epoch 419/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 306.8394 - val_loss: 437.7295\n",
            "Epoch 420/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 307.4881 - val_loss: 439.6079\n",
            "Epoch 421/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 306.5271 - val_loss: 437.4917\n",
            "Epoch 422/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 308.4979 - val_loss: 434.7553\n",
            "Epoch 423/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 306.1969 - val_loss: 439.8222\n",
            "Epoch 424/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 307.3112 - val_loss: 440.0917\n",
            "Epoch 425/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 305.9736 - val_loss: 437.1710\n",
            "Epoch 426/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 307.0814 - val_loss: 441.5781\n",
            "Epoch 427/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 305.8682 - val_loss: 434.9823\n",
            "Epoch 428/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 305.9045 - val_loss: 436.7118\n",
            "Epoch 429/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 305.9104 - val_loss: 439.6026\n",
            "Epoch 430/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 305.7920 - val_loss: 435.6964\n",
            "Epoch 431/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 304.5655 - val_loss: 437.1277\n",
            "Epoch 432/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 305.4114 - val_loss: 440.8141\n",
            "Epoch 433/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 304.9779 - val_loss: 434.3921\n",
            "Epoch 434/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 306.1641 - val_loss: 437.1316\n",
            "Epoch 435/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 305.7670 - val_loss: 438.5900\n",
            "Epoch 436/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 304.3761 - val_loss: 437.0390\n",
            "Epoch 437/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 305.7323 - val_loss: 438.5978\n",
            "Epoch 438/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 303.2581 - val_loss: 432.0857\n",
            "Epoch 439/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 305.1086 - val_loss: 432.3144\n",
            "Epoch 440/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 303.7031 - val_loss: 435.1213\n",
            "Epoch 441/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 303.6114 - val_loss: 433.9293\n",
            "Epoch 442/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 304.7153 - val_loss: 434.0114\n",
            "Epoch 443/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 304.2935 - val_loss: 437.8705\n",
            "Epoch 444/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 302.7232 - val_loss: 432.8207\n",
            "Epoch 445/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 303.7168 - val_loss: 431.5982\n",
            "Epoch 446/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 303.8049 - val_loss: 437.6914\n",
            "Epoch 447/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 303.8275 - val_loss: 432.1335\n",
            "Epoch 448/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 302.3678 - val_loss: 431.5564\n",
            "Epoch 449/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 302.9403 - val_loss: 431.2953\n",
            "Epoch 450/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 303.1609 - val_loss: 435.0910\n",
            "Epoch 451/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 302.7261 - val_loss: 436.2881\n",
            "Epoch 452/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 301.3587 - val_loss: 435.2745\n",
            "Epoch 453/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 302.4198 - val_loss: 433.5400\n",
            "Epoch 454/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 301.4739 - val_loss: 430.4707\n",
            "Epoch 455/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 301.1855 - val_loss: 432.6478\n",
            "Epoch 456/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 301.1220 - val_loss: 431.5411\n",
            "Epoch 457/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 302.0510 - val_loss: 428.0923\n",
            "Epoch 458/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 300.8371 - val_loss: 433.3457\n",
            "Epoch 459/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 301.8840 - val_loss: 428.8292\n",
            "Epoch 460/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 300.6836 - val_loss: 434.0481\n",
            "Epoch 461/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 300.8797 - val_loss: 431.6927\n",
            "Epoch 462/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 301.2148 - val_loss: 429.6090\n",
            "Epoch 463/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 301.6038 - val_loss: 430.2186\n",
            "Epoch 464/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 299.8689 - val_loss: 431.3922\n",
            "Epoch 465/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 299.8390 - val_loss: 430.1582\n",
            "Epoch 466/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 300.8932 - val_loss: 427.5749\n",
            "Epoch 467/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 299.5917 - val_loss: 430.8141\n",
            "Epoch 468/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 299.9118 - val_loss: 434.0281\n",
            "Epoch 469/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 299.3043 - val_loss: 428.9645\n",
            "Epoch 470/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 303.5658 - val_loss: 435.5119\n",
            "Epoch 471/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 301.1700 - val_loss: 437.6046\n",
            "Epoch 472/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 299.2743 - val_loss: 426.4810\n",
            "Epoch 473/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 298.7777 - val_loss: 433.9786\n",
            "Epoch 474/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 299.1886 - val_loss: 430.0874\n",
            "Epoch 475/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 299.6359 - val_loss: 430.3150\n",
            "Epoch 476/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 297.8110 - val_loss: 427.5157\n",
            "Epoch 477/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 298.0182 - val_loss: 427.8010\n",
            "Epoch 478/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 298.9635 - val_loss: 431.3452\n",
            "Epoch 479/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 298.5759 - val_loss: 427.6031\n",
            "Epoch 480/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 297.2092 - val_loss: 427.0260\n",
            "Epoch 481/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 297.6042 - val_loss: 425.4901\n",
            "Epoch 482/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 298.1135 - val_loss: 429.4682\n",
            "Epoch 483/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 297.7335 - val_loss: 425.3776\n",
            "Epoch 484/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 297.5662 - val_loss: 425.8510\n",
            "Epoch 485/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 297.9140 - val_loss: 432.0527\n",
            "Epoch 486/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 296.4107 - val_loss: 426.3093\n",
            "Epoch 487/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 299.1161 - val_loss: 423.5380\n",
            "Epoch 488/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 298.4102 - val_loss: 428.9936\n",
            "Epoch 489/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 296.1324 - val_loss: 427.3781\n",
            "Epoch 490/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 297.1424 - val_loss: 426.7888\n",
            "Epoch 491/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 295.9883 - val_loss: 424.9814\n",
            "Epoch 492/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 295.5844 - val_loss: 427.8158\n",
            "Epoch 493/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 295.5985 - val_loss: 423.9326\n",
            "Epoch 494/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 295.5697 - val_loss: 428.9972\n",
            "Epoch 495/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 295.9280 - val_loss: 429.2278\n",
            "Epoch 496/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 295.6221 - val_loss: 424.2629\n",
            "Epoch 497/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 294.5665 - val_loss: 425.1850\n",
            "Epoch 498/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 297.0720 - val_loss: 422.2225\n",
            "Epoch 499/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 296.4113 - val_loss: 421.6512\n",
            "Epoch 500/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 294.3448 - val_loss: 423.5387\n",
            "Epoch 501/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 295.1079 - val_loss: 424.3837\n",
            "Epoch 502/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 294.0114 - val_loss: 421.9991\n",
            "Epoch 503/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 293.9905 - val_loss: 422.4560\n",
            "Epoch 504/1000\n",
            "1114/1114 [==============================] - 0s 108us/step - loss: 294.0116 - val_loss: 421.8330\n",
            "Epoch 505/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 295.2662 - val_loss: 422.8453\n",
            "Epoch 506/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 294.0530 - val_loss: 422.9330\n",
            "Epoch 507/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 293.3908 - val_loss: 422.7821\n",
            "Epoch 508/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 295.2240 - val_loss: 419.6607\n",
            "Epoch 509/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 293.3259 - val_loss: 422.2382\n",
            "Epoch 510/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 294.7268 - val_loss: 423.5824\n",
            "Epoch 511/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 293.7021 - val_loss: 420.2090\n",
            "Epoch 512/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 291.9780 - val_loss: 421.6442\n",
            "Epoch 513/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 293.0453 - val_loss: 421.5225\n",
            "Epoch 514/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 292.3340 - val_loss: 419.9979\n",
            "Epoch 515/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 291.9615 - val_loss: 421.9270\n",
            "Epoch 516/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 292.4310 - val_loss: 419.0103\n",
            "Epoch 517/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 293.4293 - val_loss: 425.3644\n",
            "Epoch 518/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 291.7761 - val_loss: 422.9311\n",
            "Epoch 519/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 292.3882 - val_loss: 421.6212\n",
            "Epoch 520/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 291.8617 - val_loss: 418.4209\n",
            "Epoch 521/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 291.6691 - val_loss: 420.9188\n",
            "Epoch 522/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 291.7238 - val_loss: 420.7233\n",
            "Epoch 523/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 291.6171 - val_loss: 424.1006\n",
            "Epoch 524/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 294.5538 - val_loss: 424.5483\n",
            "Epoch 525/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 290.8173 - val_loss: 416.8108\n",
            "Epoch 526/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 292.0008 - val_loss: 417.4202\n",
            "Epoch 527/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 290.9633 - val_loss: 417.3581\n",
            "Epoch 528/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 289.9285 - val_loss: 418.8718\n",
            "Epoch 529/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 292.4462 - val_loss: 424.8340\n",
            "Epoch 530/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 290.6733 - val_loss: 420.0442\n",
            "Epoch 531/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 290.0064 - val_loss: 418.3155\n",
            "Epoch 532/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 289.1110 - val_loss: 417.4794\n",
            "Epoch 533/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 289.1810 - val_loss: 419.9619\n",
            "Epoch 534/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 289.5121 - val_loss: 415.8487\n",
            "Epoch 535/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 289.7182 - val_loss: 418.4363\n",
            "Epoch 536/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 289.9791 - val_loss: 419.9714\n",
            "Epoch 537/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 289.1739 - val_loss: 416.8603\n",
            "Epoch 538/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 289.1235 - val_loss: 415.6280\n",
            "Epoch 539/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 288.9576 - val_loss: 414.0348\n",
            "Epoch 540/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 289.2590 - val_loss: 416.1297\n",
            "Epoch 541/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 289.5959 - val_loss: 414.2506\n",
            "Epoch 542/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 287.9375 - val_loss: 418.3323\n",
            "Epoch 543/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 287.8069 - val_loss: 421.1730\n",
            "Epoch 544/1000\n",
            "1114/1114 [==============================] - 0s 110us/step - loss: 288.0649 - val_loss: 416.2431\n",
            "Epoch 545/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 288.9822 - val_loss: 415.8174\n",
            "Epoch 546/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 288.0746 - val_loss: 413.2831\n",
            "Epoch 547/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 286.9887 - val_loss: 418.3108\n",
            "Epoch 548/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 286.6980 - val_loss: 412.7052\n",
            "Epoch 549/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 287.8698 - val_loss: 413.4836\n",
            "Epoch 550/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 286.5424 - val_loss: 417.3535\n",
            "Epoch 551/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 287.7614 - val_loss: 412.9430\n",
            "Epoch 552/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 288.9857 - val_loss: 415.3267\n",
            "Epoch 553/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 287.2743 - val_loss: 413.7073\n",
            "Epoch 554/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 286.9673 - val_loss: 413.0526\n",
            "Epoch 555/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 286.0073 - val_loss: 417.9647\n",
            "Epoch 556/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 285.9864 - val_loss: 411.6849\n",
            "Epoch 557/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 286.8503 - val_loss: 413.2340\n",
            "Epoch 558/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 285.8177 - val_loss: 414.4516\n",
            "Epoch 559/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 285.7273 - val_loss: 411.5355\n",
            "Epoch 560/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 285.0738 - val_loss: 415.1859\n",
            "Epoch 561/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 285.7522 - val_loss: 412.8925\n",
            "Epoch 562/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 284.7241 - val_loss: 415.2513\n",
            "Epoch 563/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 285.9382 - val_loss: 415.0581\n",
            "Epoch 564/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 284.9269 - val_loss: 411.8988\n",
            "Epoch 565/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 286.5292 - val_loss: 410.3399\n",
            "Epoch 566/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 285.7751 - val_loss: 411.2287\n",
            "Epoch 567/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 283.8687 - val_loss: 413.4660\n",
            "Epoch 568/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 284.2341 - val_loss: 411.2160\n",
            "Epoch 569/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 284.1184 - val_loss: 415.1156\n",
            "Epoch 570/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 283.6120 - val_loss: 414.0350\n",
            "Epoch 571/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 284.4582 - val_loss: 412.6909\n",
            "Epoch 572/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 283.7839 - val_loss: 411.2014\n",
            "Epoch 573/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 283.5029 - val_loss: 410.8289\n",
            "Epoch 574/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 284.4041 - val_loss: 411.3332\n",
            "Epoch 575/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 283.3149 - val_loss: 410.7559\n",
            "Epoch 576/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 282.9161 - val_loss: 411.8445\n",
            "Epoch 577/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 283.0486 - val_loss: 410.8229\n",
            "Epoch 578/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 282.7109 - val_loss: 409.1866\n",
            "Epoch 579/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 283.3341 - val_loss: 408.7720\n",
            "Epoch 580/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 281.8106 - val_loss: 409.9615\n",
            "Epoch 581/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 282.1251 - val_loss: 409.0804\n",
            "Epoch 582/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 282.9633 - val_loss: 414.6410\n",
            "Epoch 583/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 282.2811 - val_loss: 406.9426\n",
            "Epoch 584/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 282.5759 - val_loss: 406.2560\n",
            "Epoch 585/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 281.5712 - val_loss: 410.8539\n",
            "Epoch 586/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 280.5869 - val_loss: 407.6300\n",
            "Epoch 587/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 281.1947 - val_loss: 406.9945\n",
            "Epoch 588/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 280.4061 - val_loss: 411.9323\n",
            "Epoch 589/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 280.4522 - val_loss: 406.3311\n",
            "Epoch 590/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 280.5659 - val_loss: 404.2505\n",
            "Epoch 591/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 281.1194 - val_loss: 406.1890\n",
            "Epoch 592/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 281.1366 - val_loss: 403.4246\n",
            "Epoch 593/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 280.9481 - val_loss: 406.2432\n",
            "Epoch 594/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 280.2796 - val_loss: 403.6995\n",
            "Epoch 595/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 280.9815 - val_loss: 402.6488\n",
            "Epoch 596/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 280.1450 - val_loss: 402.3707\n",
            "Epoch 597/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 278.9757 - val_loss: 405.9828\n",
            "Epoch 598/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 279.4031 - val_loss: 404.7563\n",
            "Epoch 599/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 280.2816 - val_loss: 404.0062\n",
            "Epoch 600/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 280.5839 - val_loss: 402.3387\n",
            "Epoch 601/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 280.2572 - val_loss: 408.0346\n",
            "Epoch 602/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 278.5197 - val_loss: 404.5667\n",
            "Epoch 603/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 277.6723 - val_loss: 403.4851\n",
            "Epoch 604/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 277.6192 - val_loss: 404.8206\n",
            "Epoch 605/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 277.5355 - val_loss: 404.2741\n",
            "Epoch 606/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 277.0101 - val_loss: 405.9393\n",
            "Epoch 607/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 276.2778 - val_loss: 401.1884\n",
            "Epoch 608/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 276.3522 - val_loss: 402.4575\n",
            "Epoch 609/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 276.8844 - val_loss: 399.8197\n",
            "Epoch 610/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 276.7953 - val_loss: 398.7770\n",
            "Epoch 611/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 276.0810 - val_loss: 398.5596\n",
            "Epoch 612/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 275.2264 - val_loss: 398.8492\n",
            "Epoch 613/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 277.4695 - val_loss: 406.3550\n",
            "Epoch 614/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 277.4291 - val_loss: 406.4354\n",
            "Epoch 615/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 277.2601 - val_loss: 397.6593\n",
            "Epoch 616/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 277.5890 - val_loss: 400.7531\n",
            "Epoch 617/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 275.2033 - val_loss: 396.9916\n",
            "Epoch 618/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 275.5503 - val_loss: 398.5906\n",
            "Epoch 619/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 274.7817 - val_loss: 396.9523\n",
            "Epoch 620/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 274.8559 - val_loss: 398.4205\n",
            "Epoch 621/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 275.4840 - val_loss: 402.9019\n",
            "Epoch 622/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 274.4306 - val_loss: 398.3415\n",
            "Epoch 623/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 274.9639 - val_loss: 400.9464\n",
            "Epoch 624/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 274.3809 - val_loss: 397.3039\n",
            "Epoch 625/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 273.6924 - val_loss: 395.3780\n",
            "Epoch 626/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 274.0375 - val_loss: 399.5635\n",
            "Epoch 627/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 274.7466 - val_loss: 398.8718\n",
            "Epoch 628/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 272.7653 - val_loss: 398.7657\n",
            "Epoch 629/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 273.2597 - val_loss: 395.7785\n",
            "Epoch 630/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 273.0508 - val_loss: 397.3974\n",
            "Epoch 631/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 273.4829 - val_loss: 397.8160\n",
            "Epoch 632/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 272.0262 - val_loss: 394.7598\n",
            "Epoch 633/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 273.1998 - val_loss: 399.2632\n",
            "Epoch 634/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 272.0554 - val_loss: 392.9802\n",
            "Epoch 635/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 271.2366 - val_loss: 393.2321\n",
            "Epoch 636/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 272.8261 - val_loss: 392.0499\n",
            "Epoch 637/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 271.9741 - val_loss: 394.3929\n",
            "Epoch 638/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 272.3604 - val_loss: 392.4005\n",
            "Epoch 639/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 271.3849 - val_loss: 392.6183\n",
            "Epoch 640/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 270.5694 - val_loss: 399.3979\n",
            "Epoch 641/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 270.4276 - val_loss: 392.6392\n",
            "Epoch 642/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 273.8953 - val_loss: 397.5006\n",
            "Epoch 643/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 270.0698 - val_loss: 391.8922\n",
            "Epoch 644/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 269.8750 - val_loss: 393.2205\n",
            "Epoch 645/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 270.8579 - val_loss: 393.4575\n",
            "Epoch 646/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 272.6496 - val_loss: 393.2999\n",
            "Epoch 647/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 270.4353 - val_loss: 391.1775\n",
            "Epoch 648/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 271.0924 - val_loss: 392.0706\n",
            "Epoch 649/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 270.2154 - val_loss: 393.0916\n",
            "Epoch 650/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 269.9387 - val_loss: 390.0171\n",
            "Epoch 651/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 269.0211 - val_loss: 393.2018\n",
            "Epoch 652/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 269.3102 - val_loss: 392.0226\n",
            "Epoch 653/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 269.5846 - val_loss: 394.1797\n",
            "Epoch 654/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 270.6542 - val_loss: 395.5797\n",
            "Epoch 655/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 269.4660 - val_loss: 392.4002\n",
            "Epoch 656/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 267.9071 - val_loss: 388.3401\n",
            "Epoch 657/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 268.3873 - val_loss: 388.3101\n",
            "Epoch 658/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 267.4269 - val_loss: 390.8525\n",
            "Epoch 659/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 267.4639 - val_loss: 388.5486\n",
            "Epoch 660/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 268.5871 - val_loss: 390.1677\n",
            "Epoch 661/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 267.0221 - val_loss: 390.8114\n",
            "Epoch 662/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 269.7251 - val_loss: 386.6734\n",
            "Epoch 663/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 268.2328 - val_loss: 386.7616\n",
            "Epoch 664/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 267.4396 - val_loss: 386.4484\n",
            "Epoch 665/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 268.5029 - val_loss: 390.8439\n",
            "Epoch 666/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 265.8501 - val_loss: 388.7366\n",
            "Epoch 667/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 270.2114 - val_loss: 396.1936\n",
            "Epoch 668/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 267.0310 - val_loss: 386.7686\n",
            "Epoch 669/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 266.9470 - val_loss: 385.5012\n",
            "Epoch 670/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 265.7669 - val_loss: 386.2107\n",
            "Epoch 671/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 266.0364 - val_loss: 386.0473\n",
            "Epoch 672/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 265.8554 - val_loss: 389.4135\n",
            "Epoch 673/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 267.2955 - val_loss: 383.6633\n",
            "Epoch 674/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 265.3139 - val_loss: 388.0037\n",
            "Epoch 675/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 267.5157 - val_loss: 391.0828\n",
            "Epoch 676/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 265.8528 - val_loss: 387.2985\n",
            "Epoch 677/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 265.0324 - val_loss: 385.0361\n",
            "Epoch 678/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 265.4533 - val_loss: 384.1160\n",
            "Epoch 679/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 264.7212 - val_loss: 386.7166\n",
            "Epoch 680/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 264.6470 - val_loss: 384.5182\n",
            "Epoch 681/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 264.5214 - val_loss: 383.8368\n",
            "Epoch 682/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 265.0092 - val_loss: 384.8053\n",
            "Epoch 683/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 263.8151 - val_loss: 387.5796\n",
            "Epoch 684/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 265.2230 - val_loss: 384.1719\n",
            "Epoch 685/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 263.4010 - val_loss: 383.3793\n",
            "Epoch 686/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 264.1463 - val_loss: 381.1099\n",
            "Epoch 687/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 264.2474 - val_loss: 383.9356\n",
            "Epoch 688/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 263.3501 - val_loss: 384.5371\n",
            "Epoch 689/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 263.4052 - val_loss: 382.5952\n",
            "Epoch 690/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 263.7125 - val_loss: 384.2878\n",
            "Epoch 691/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 264.8390 - val_loss: 380.5152\n",
            "Epoch 692/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 263.0000 - val_loss: 381.4866\n",
            "Epoch 693/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 262.0875 - val_loss: 382.6759\n",
            "Epoch 694/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 262.1700 - val_loss: 380.1372\n",
            "Epoch 695/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 263.4324 - val_loss: 387.3036\n",
            "Epoch 696/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 263.6399 - val_loss: 384.6658\n",
            "Epoch 697/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 263.6180 - val_loss: 385.9440\n",
            "Epoch 698/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 261.5465 - val_loss: 378.2533\n",
            "Epoch 699/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 262.1451 - val_loss: 384.4947\n",
            "Epoch 700/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 261.6571 - val_loss: 378.5207\n",
            "Epoch 701/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 262.5241 - val_loss: 379.9263\n",
            "Epoch 702/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 263.4442 - val_loss: 384.7155\n",
            "Epoch 703/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 262.5412 - val_loss: 380.5795\n",
            "Epoch 704/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 260.5664 - val_loss: 379.2886\n",
            "Epoch 705/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 261.1740 - val_loss: 379.6604\n",
            "Epoch 706/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 260.6903 - val_loss: 383.9908\n",
            "Epoch 707/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 264.7074 - val_loss: 376.6769\n",
            "Epoch 708/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 260.5778 - val_loss: 376.7113\n",
            "Epoch 709/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 260.2749 - val_loss: 377.5614\n",
            "Epoch 710/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 259.8708 - val_loss: 383.2168\n",
            "Epoch 711/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 260.6003 - val_loss: 378.5086\n",
            "Epoch 712/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 263.1548 - val_loss: 374.4658\n",
            "Epoch 713/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 260.6590 - val_loss: 380.9086\n",
            "Epoch 714/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 261.9286 - val_loss: 377.7978\n",
            "Epoch 715/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 259.7594 - val_loss: 376.4749\n",
            "Epoch 716/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 259.4658 - val_loss: 377.9062\n",
            "Epoch 717/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 259.5645 - val_loss: 377.7814\n",
            "Epoch 718/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 258.2006 - val_loss: 378.5569\n",
            "Epoch 719/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 258.7220 - val_loss: 376.2507\n",
            "Epoch 720/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 260.4000 - val_loss: 376.7949\n",
            "Epoch 721/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 258.9861 - val_loss: 376.6250\n",
            "Epoch 722/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 258.9068 - val_loss: 375.1583\n",
            "Epoch 723/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 260.5173 - val_loss: 372.2557\n",
            "Epoch 724/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 258.4934 - val_loss: 373.3478\n",
            "Epoch 725/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 258.0789 - val_loss: 378.1364\n",
            "Epoch 726/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 257.5830 - val_loss: 377.0010\n",
            "Epoch 727/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 257.8352 - val_loss: 371.8102\n",
            "Epoch 728/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 257.5038 - val_loss: 371.8677\n",
            "Epoch 729/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 257.6031 - val_loss: 374.1627\n",
            "Epoch 730/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 258.9258 - val_loss: 371.8975\n",
            "Epoch 731/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 257.3845 - val_loss: 372.8457\n",
            "Epoch 732/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 256.9460 - val_loss: 372.4021\n",
            "Epoch 733/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 256.3542 - val_loss: 373.6023\n",
            "Epoch 734/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 257.1318 - val_loss: 373.0322\n",
            "Epoch 735/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 256.2566 - val_loss: 372.5891\n",
            "Epoch 736/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 257.0704 - val_loss: 377.1899\n",
            "Epoch 737/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 257.2026 - val_loss: 371.4354\n",
            "Epoch 738/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 255.6791 - val_loss: 370.2270\n",
            "Epoch 739/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 255.5656 - val_loss: 370.7744\n",
            "Epoch 740/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 256.8913 - val_loss: 368.2800\n",
            "Epoch 741/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 255.3872 - val_loss: 371.2734\n",
            "Epoch 742/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 254.7534 - val_loss: 369.6113\n",
            "Epoch 743/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 259.2256 - val_loss: 376.5041\n",
            "Epoch 744/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 256.0604 - val_loss: 371.9089\n",
            "Epoch 745/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 254.9401 - val_loss: 369.1391\n",
            "Epoch 746/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 255.7996 - val_loss: 369.6528\n",
            "Epoch 747/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 254.7926 - val_loss: 369.4083\n",
            "Epoch 748/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 254.6634 - val_loss: 370.2686\n",
            "Epoch 749/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 253.7038 - val_loss: 368.2017\n",
            "Epoch 750/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 254.4221 - val_loss: 368.0613\n",
            "Epoch 751/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 253.7611 - val_loss: 367.2752\n",
            "Epoch 752/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 254.6701 - val_loss: 367.9846\n",
            "Epoch 753/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 255.0563 - val_loss: 368.7611\n",
            "Epoch 754/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 254.2699 - val_loss: 367.8204\n",
            "Epoch 755/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 253.1014 - val_loss: 365.7043\n",
            "Epoch 756/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 253.6370 - val_loss: 366.9168\n",
            "Epoch 757/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 253.1903 - val_loss: 365.9653\n",
            "Epoch 758/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 252.7665 - val_loss: 368.7981\n",
            "Epoch 759/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 253.5877 - val_loss: 365.1664\n",
            "Epoch 760/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 254.7889 - val_loss: 366.7095\n",
            "Epoch 761/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 253.1798 - val_loss: 364.8121\n",
            "Epoch 762/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 254.2118 - val_loss: 367.7961\n",
            "Epoch 763/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 252.4427 - val_loss: 364.4152\n",
            "Epoch 764/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 252.5382 - val_loss: 362.5726\n",
            "Epoch 765/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 252.3619 - val_loss: 364.9776\n",
            "Epoch 766/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 253.4312 - val_loss: 368.2554\n",
            "Epoch 767/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 252.7666 - val_loss: 371.6904\n",
            "Epoch 768/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 255.9603 - val_loss: 369.4162\n",
            "Epoch 769/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 253.0871 - val_loss: 367.8075\n",
            "Epoch 770/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 251.4454 - val_loss: 362.4784\n",
            "Epoch 771/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 251.4799 - val_loss: 362.8851\n",
            "Epoch 772/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 252.8546 - val_loss: 367.9910\n",
            "Epoch 773/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 251.0848 - val_loss: 361.9579\n",
            "Epoch 774/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 250.3970 - val_loss: 360.9142\n",
            "Epoch 775/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 251.1205 - val_loss: 364.9545\n",
            "Epoch 776/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 252.1056 - val_loss: 364.7116\n",
            "Epoch 777/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 250.6061 - val_loss: 362.5781\n",
            "Epoch 778/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 249.9333 - val_loss: 359.0247\n",
            "Epoch 779/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 251.4158 - val_loss: 360.0416\n",
            "Epoch 780/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 252.2183 - val_loss: 359.1133\n",
            "Epoch 781/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 249.3082 - val_loss: 363.3071\n",
            "Epoch 782/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 249.6358 - val_loss: 360.5369\n",
            "Epoch 783/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 250.9092 - val_loss: 368.6741\n",
            "Epoch 784/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 250.5407 - val_loss: 357.0958\n",
            "Epoch 785/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 249.8460 - val_loss: 358.8100\n",
            "Epoch 786/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 252.1398 - val_loss: 357.7949\n",
            "Epoch 787/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 249.2725 - val_loss: 359.0640\n",
            "Epoch 788/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 249.6948 - val_loss: 357.8052\n",
            "Epoch 789/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 249.3241 - val_loss: 360.6087\n",
            "Epoch 790/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 251.5233 - val_loss: 359.1342\n",
            "Epoch 791/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 248.0408 - val_loss: 362.1178\n",
            "Epoch 792/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 248.6529 - val_loss: 360.1799\n",
            "Epoch 793/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 249.6297 - val_loss: 357.4156\n",
            "Epoch 794/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 248.6402 - val_loss: 359.2163\n",
            "Epoch 795/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 249.6415 - val_loss: 355.5717\n",
            "Epoch 796/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 248.8959 - val_loss: 359.3950\n",
            "Epoch 797/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 247.3703 - val_loss: 358.5750\n",
            "Epoch 798/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 248.6254 - val_loss: 360.3063\n",
            "Epoch 799/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 247.2447 - val_loss: 355.6379\n",
            "Epoch 800/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 247.0932 - val_loss: 355.1116\n",
            "Epoch 801/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 247.4953 - val_loss: 355.8415\n",
            "Epoch 802/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 250.3573 - val_loss: 363.4164\n",
            "Epoch 803/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 247.7672 - val_loss: 361.6452\n",
            "Epoch 804/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 249.6209 - val_loss: 354.9820\n",
            "Epoch 805/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 247.6187 - val_loss: 353.1004\n",
            "Epoch 806/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 246.4866 - val_loss: 358.7221\n",
            "Epoch 807/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 250.4255 - val_loss: 358.5597\n",
            "Epoch 808/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 246.6122 - val_loss: 355.8486\n",
            "Epoch 809/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 247.3341 - val_loss: 357.4116\n",
            "Epoch 810/1000\n",
            "1114/1114 [==============================] - 0s 101us/step - loss: 245.9096 - val_loss: 354.1258\n",
            "Epoch 811/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 246.2298 - val_loss: 352.8134\n",
            "Epoch 812/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 246.2192 - val_loss: 351.3676\n",
            "Epoch 813/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 245.5794 - val_loss: 352.5457\n",
            "Epoch 814/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 245.4211 - val_loss: 353.0782\n",
            "Epoch 815/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 245.3937 - val_loss: 353.7541\n",
            "Epoch 816/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 245.5148 - val_loss: 357.1308\n",
            "Epoch 817/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 245.3154 - val_loss: 353.3409\n",
            "Epoch 818/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 245.7590 - val_loss: 355.9551\n",
            "Epoch 819/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 244.6959 - val_loss: 353.0712\n",
            "Epoch 820/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 246.6110 - val_loss: 350.1772\n",
            "Epoch 821/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 244.5779 - val_loss: 350.0886\n",
            "Epoch 822/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 244.9629 - val_loss: 351.7024\n",
            "Epoch 823/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 243.4702 - val_loss: 350.2662\n",
            "Epoch 824/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 244.4303 - val_loss: 348.6566\n",
            "Epoch 825/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 243.2257 - val_loss: 350.8378\n",
            "Epoch 826/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 244.0862 - val_loss: 354.3990\n",
            "Epoch 827/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 244.3212 - val_loss: 354.2874\n",
            "Epoch 828/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 243.4614 - val_loss: 349.9320\n",
            "Epoch 829/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 243.1489 - val_loss: 349.7563\n",
            "Epoch 830/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 243.2024 - val_loss: 347.3451\n",
            "Epoch 831/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 243.8313 - val_loss: 349.6440\n",
            "Epoch 832/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 244.4171 - val_loss: 346.6696\n",
            "Epoch 833/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 243.1276 - val_loss: 346.3213\n",
            "Epoch 834/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 242.8568 - val_loss: 346.2980\n",
            "Epoch 835/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 243.7361 - val_loss: 345.7402\n",
            "Epoch 836/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 242.2975 - val_loss: 349.3060\n",
            "Epoch 837/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 241.8649 - val_loss: 345.3039\n",
            "Epoch 838/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 243.7766 - val_loss: 346.6032\n",
            "Epoch 839/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 242.0786 - val_loss: 349.5258\n",
            "Epoch 840/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 241.4444 - val_loss: 349.2709\n",
            "Epoch 841/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 242.4835 - val_loss: 349.0042\n",
            "Epoch 842/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 241.2933 - val_loss: 345.0211\n",
            "Epoch 843/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 245.5964 - val_loss: 348.8112\n",
            "Epoch 844/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 239.7147 - val_loss: 343.6126\n",
            "Epoch 845/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 241.4050 - val_loss: 346.8248\n",
            "Epoch 846/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 240.0714 - val_loss: 347.1797\n",
            "Epoch 847/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 240.5427 - val_loss: 344.1930\n",
            "Epoch 848/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 240.6253 - val_loss: 347.7005\n",
            "Epoch 849/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 240.9550 - val_loss: 345.7793\n",
            "Epoch 850/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 239.6290 - val_loss: 343.4821\n",
            "Epoch 851/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 241.8159 - val_loss: 348.7885\n",
            "Epoch 852/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 240.1020 - val_loss: 342.9935\n",
            "Epoch 853/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 239.9866 - val_loss: 342.9632\n",
            "Epoch 854/1000\n",
            "1114/1114 [==============================] - 0s 116us/step - loss: 241.4932 - val_loss: 346.9144\n",
            "Epoch 855/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 239.3134 - val_loss: 341.8014\n",
            "Epoch 856/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 239.2498 - val_loss: 343.9352\n",
            "Epoch 857/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 238.7763 - val_loss: 342.1172\n",
            "Epoch 858/1000\n",
            "1114/1114 [==============================] - 0s 108us/step - loss: 239.7957 - val_loss: 347.5133\n",
            "Epoch 859/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 239.1786 - val_loss: 341.3375\n",
            "Epoch 860/1000\n",
            "1114/1114 [==============================] - 0s 90us/step - loss: 237.8922 - val_loss: 341.8673\n",
            "Epoch 861/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 238.8356 - val_loss: 341.7268\n",
            "Epoch 862/1000\n",
            "1114/1114 [==============================] - 0s 90us/step - loss: 240.8279 - val_loss: 346.8463\n",
            "Epoch 863/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 238.5704 - val_loss: 344.2138\n",
            "Epoch 864/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 238.8074 - val_loss: 342.5375\n",
            "Epoch 865/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 239.8036 - val_loss: 348.2686\n",
            "Epoch 866/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 238.7711 - val_loss: 340.0336\n",
            "Epoch 867/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 240.1736 - val_loss: 343.5540\n",
            "Epoch 868/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 238.5167 - val_loss: 340.4712\n",
            "Epoch 869/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 238.4977 - val_loss: 344.0747\n",
            "Epoch 870/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 237.0452 - val_loss: 338.3678\n",
            "Epoch 871/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 237.0057 - val_loss: 339.9161\n",
            "Epoch 872/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 236.6818 - val_loss: 340.0461\n",
            "Epoch 873/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 237.6890 - val_loss: 339.6076\n",
            "Epoch 874/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 239.0246 - val_loss: 336.9560\n",
            "Epoch 875/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 237.1221 - val_loss: 338.1353\n",
            "Epoch 876/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 237.0836 - val_loss: 336.3936\n",
            "Epoch 877/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 237.8681 - val_loss: 335.1361\n",
            "Epoch 878/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 235.9714 - val_loss: 336.3804\n",
            "Epoch 879/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 235.2429 - val_loss: 334.2767\n",
            "Epoch 880/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 236.2244 - val_loss: 334.0462\n",
            "Epoch 881/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 235.8037 - val_loss: 334.0030\n",
            "Epoch 882/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 235.5652 - val_loss: 336.4882\n",
            "Epoch 883/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 234.4186 - val_loss: 333.9028\n",
            "Epoch 884/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 234.6432 - val_loss: 337.6900\n",
            "Epoch 885/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 235.9728 - val_loss: 342.6639\n",
            "Epoch 886/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 235.5394 - val_loss: 340.2798\n",
            "Epoch 887/1000\n",
            "1114/1114 [==============================] - 0s 103us/step - loss: 235.8056 - val_loss: 341.2952\n",
            "Epoch 888/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 234.8031 - val_loss: 336.4929\n",
            "Epoch 889/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 233.8927 - val_loss: 331.6978\n",
            "Epoch 890/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 234.4742 - val_loss: 332.8601\n",
            "Epoch 891/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 234.4366 - val_loss: 331.8690\n",
            "Epoch 892/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 236.2388 - val_loss: 334.4740\n",
            "Epoch 893/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 233.7007 - val_loss: 339.5704\n",
            "Epoch 894/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 233.1051 - val_loss: 331.8764\n",
            "Epoch 895/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 232.8229 - val_loss: 331.4285\n",
            "Epoch 896/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 232.0209 - val_loss: 329.0110\n",
            "Epoch 897/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 233.0589 - val_loss: 331.4946\n",
            "Epoch 898/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 234.0896 - val_loss: 335.9282\n",
            "Epoch 899/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 233.7019 - val_loss: 330.7679\n",
            "Epoch 900/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 231.2059 - val_loss: 330.0820\n",
            "Epoch 901/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 232.6793 - val_loss: 333.5939\n",
            "Epoch 902/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 231.2787 - val_loss: 331.8366\n",
            "Epoch 903/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 231.3582 - val_loss: 332.1537\n",
            "Epoch 904/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 230.3027 - val_loss: 329.4840\n",
            "Epoch 905/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 230.2978 - val_loss: 327.1640\n",
            "Epoch 906/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 232.3489 - val_loss: 330.3199\n",
            "Epoch 907/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 230.5744 - val_loss: 331.6255\n",
            "Epoch 908/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 231.5797 - val_loss: 328.5294\n",
            "Epoch 909/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 231.6478 - val_loss: 329.3114\n",
            "Epoch 910/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 229.3240 - val_loss: 325.8757\n",
            "Epoch 911/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 229.7038 - val_loss: 325.8554\n",
            "Epoch 912/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 229.1070 - val_loss: 326.0139\n",
            "Epoch 913/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 229.4027 - val_loss: 334.5296\n",
            "Epoch 914/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 229.3860 - val_loss: 328.5208\n",
            "Epoch 915/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 229.1303 - val_loss: 323.5186\n",
            "Epoch 916/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 230.3979 - val_loss: 323.6334\n",
            "Epoch 917/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 227.9912 - val_loss: 327.8503\n",
            "Epoch 918/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 229.1040 - val_loss: 323.0569\n",
            "Epoch 919/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 232.3865 - val_loss: 322.7606\n",
            "Epoch 920/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 228.3863 - val_loss: 322.6242\n",
            "Epoch 921/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 230.9822 - val_loss: 323.3913\n",
            "Epoch 922/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 227.8491 - val_loss: 326.2764\n",
            "Epoch 923/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 228.8680 - val_loss: 328.0125\n",
            "Epoch 924/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 228.0340 - val_loss: 324.3719\n",
            "Epoch 925/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 228.8410 - val_loss: 321.3721\n",
            "Epoch 926/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 229.6037 - val_loss: 320.4493\n",
            "Epoch 927/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 227.8256 - val_loss: 322.9391\n",
            "Epoch 928/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 228.6031 - val_loss: 326.6018\n",
            "Epoch 929/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 228.0723 - val_loss: 320.6992\n",
            "Epoch 930/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 226.2075 - val_loss: 320.2027\n",
            "Epoch 931/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 228.2495 - val_loss: 320.5921\n",
            "Epoch 932/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 228.0429 - val_loss: 321.1139\n",
            "Epoch 933/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 224.7838 - val_loss: 326.5997\n",
            "Epoch 934/1000\n",
            "1114/1114 [==============================] - 0s 105us/step - loss: 227.1026 - val_loss: 320.6533\n",
            "Epoch 935/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 227.7989 - val_loss: 320.0118\n",
            "Epoch 936/1000\n",
            "1114/1114 [==============================] - 0s 102us/step - loss: 226.8765 - val_loss: 318.5095\n",
            "Epoch 937/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 225.4140 - val_loss: 320.2498\n",
            "Epoch 938/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 226.4084 - val_loss: 317.5550\n",
            "Epoch 939/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 225.7489 - val_loss: 317.6982\n",
            "Epoch 940/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 225.0689 - val_loss: 321.3096\n",
            "Epoch 941/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 225.8737 - val_loss: 316.7760\n",
            "Epoch 942/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 224.1159 - val_loss: 318.3003\n",
            "Epoch 943/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 225.4798 - val_loss: 315.9039\n",
            "Epoch 944/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 224.4175 - val_loss: 317.5199\n",
            "Epoch 945/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 224.7140 - val_loss: 316.5000\n",
            "Epoch 946/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 223.5503 - val_loss: 316.6040\n",
            "Epoch 947/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 224.3167 - val_loss: 315.6610\n",
            "Epoch 948/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 223.8132 - val_loss: 317.3504\n",
            "Epoch 949/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 222.7165 - val_loss: 314.7978\n",
            "Epoch 950/1000\n",
            "1114/1114 [==============================] - 0s 91us/step - loss: 226.0622 - val_loss: 314.5500\n",
            "Epoch 951/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 223.0092 - val_loss: 315.7520\n",
            "Epoch 952/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 224.6064 - val_loss: 315.1412\n",
            "Epoch 953/1000\n",
            "1114/1114 [==============================] - 0s 99us/step - loss: 223.7523 - val_loss: 315.2845\n",
            "Epoch 954/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 224.0852 - val_loss: 324.9524\n",
            "Epoch 955/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 223.3047 - val_loss: 314.7577\n",
            "Epoch 956/1000\n",
            "1114/1114 [==============================] - 0s 110us/step - loss: 221.8859 - val_loss: 316.4007\n",
            "Epoch 957/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 223.2339 - val_loss: 312.6208\n",
            "Epoch 958/1000\n",
            "1114/1114 [==============================] - 0s 100us/step - loss: 221.8318 - val_loss: 312.4834\n",
            "Epoch 959/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 221.0469 - val_loss: 316.4708\n",
            "Epoch 960/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 222.3660 - val_loss: 313.7335\n",
            "Epoch 961/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 225.1680 - val_loss: 319.2608\n",
            "Epoch 962/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 222.3254 - val_loss: 312.3648\n",
            "Epoch 963/1000\n",
            "1114/1114 [==============================] - 0s 110us/step - loss: 221.4619 - val_loss: 311.3697\n",
            "Epoch 964/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 221.4750 - val_loss: 311.6303\n",
            "Epoch 965/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 220.7385 - val_loss: 311.5210\n",
            "Epoch 966/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 220.4350 - val_loss: 311.5417\n",
            "Epoch 967/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 221.1252 - val_loss: 308.8915\n",
            "Epoch 968/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 222.5960 - val_loss: 309.7176\n",
            "Epoch 969/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 220.5836 - val_loss: 312.8583\n",
            "Epoch 970/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 224.7197 - val_loss: 313.3511\n",
            "Epoch 971/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 220.0454 - val_loss: 315.9116\n",
            "Epoch 972/1000\n",
            "1114/1114 [==============================] - 0s 106us/step - loss: 219.0351 - val_loss: 308.6905\n",
            "Epoch 973/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 219.5144 - val_loss: 308.3838\n",
            "Epoch 974/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 218.3144 - val_loss: 312.4065\n",
            "Epoch 975/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 220.8018 - val_loss: 308.7896\n",
            "Epoch 976/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 221.1986 - val_loss: 311.9568\n",
            "Epoch 977/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 221.1244 - val_loss: 309.9090\n",
            "Epoch 978/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 219.6218 - val_loss: 306.4837\n",
            "Epoch 979/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 221.3585 - val_loss: 308.7194\n",
            "Epoch 980/1000\n",
            "1114/1114 [==============================] - 0s 97us/step - loss: 217.5138 - val_loss: 309.9956\n",
            "Epoch 981/1000\n",
            "1114/1114 [==============================] - 0s 96us/step - loss: 218.6948 - val_loss: 305.1662\n",
            "Epoch 982/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 218.7263 - val_loss: 308.6456\n",
            "Epoch 983/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 217.7415 - val_loss: 304.6260\n",
            "Epoch 984/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 218.5924 - val_loss: 309.8499\n",
            "Epoch 985/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 218.1466 - val_loss: 305.8002\n",
            "Epoch 986/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 219.2915 - val_loss: 305.8620\n",
            "Epoch 987/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 216.9858 - val_loss: 307.0602\n",
            "Epoch 988/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 216.0429 - val_loss: 305.1545\n",
            "Epoch 989/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 215.8335 - val_loss: 306.2796\n",
            "Epoch 990/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 216.7335 - val_loss: 303.8855\n",
            "Epoch 991/1000\n",
            "1114/1114 [==============================] - 0s 104us/step - loss: 216.7000 - val_loss: 304.9050\n",
            "Epoch 992/1000\n",
            "1114/1114 [==============================] - 0s 95us/step - loss: 215.6402 - val_loss: 303.9187\n",
            "Epoch 993/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 216.6721 - val_loss: 306.8514\n",
            "Epoch 994/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 217.3389 - val_loss: 302.8087\n",
            "Epoch 995/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 215.2745 - val_loss: 306.0307\n",
            "Epoch 996/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 219.7211 - val_loss: 306.3503\n",
            "Epoch 997/1000\n",
            "1114/1114 [==============================] - 0s 98us/step - loss: 215.5906 - val_loss: 301.0131\n",
            "Epoch 998/1000\n",
            "1114/1114 [==============================] - 0s 93us/step - loss: 215.0702 - val_loss: 301.1684\n",
            "Epoch 999/1000\n",
            "1114/1114 [==============================] - 0s 94us/step - loss: 214.8343 - val_loss: 299.9985\n",
            "Epoch 1000/1000\n",
            "1114/1114 [==============================] - 0s 92us/step - loss: 215.7419 - val_loss: 306.9843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8qqMndYh3F9y",
        "colab_type": "code",
        "outputId": "d718c9a1-392a-4df2-bb8c-14a0cc0d203c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "tr = hist.history['loss']\n",
        "val_ls = hist.history['val_loss']\n",
        "plt.plot(tr[1:])\n",
        "plt.plot(val_ls[1:])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf141e4a58>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmUXOV95vHv71ZV76taLam1gBAI\nhMAYsMwSexLGxGxJBifj8YFJYuI4B88JnnFyPONAMmecOMOJk0nM2JOEYzwmxonHmLEdm8MQYxnj\nnU1gNolFQkJIQlK31PtW62/+eG9LhaiuXtStlm4/n3PqdNV7b916b1+pnn6Xe6+5OyIisvhEC10B\nERFZGAoAEZFFSgEgIrJIKQBERBYpBYCIyCKlABARWaQUACIii5QCQERkkVIAiIgsUumFrkA1S5cu\n9bVr1y50NURETilPPfXUIXfvnGq9kzoA1q5dy5YtWxa6GiIipxQz2z2d9absAjKzOjN7wsyeNbOt\nZvZncfmXzGyXmT0TPy6My83MPmdmO8zsOTO7uGxbN5nZ9vhx02x3TkREjt90WgBZ4D3uPmxmGeAn\nZvYv8bL/4u5fP2b9a4H18eNS4E7gUjNbAnwS2AQ48JSZ3e/ufXOxIyIiMjNTtgA8GI5fZuJHtUuI\nXg98OX7fY0CbmXUBVwOb3b03/tLfDFxzfNUXEZHZmtYsIDNLmdkzQDfhS/zxeNHtcTfPHWZWG5et\nAvaUvX1vXDZZuYiILIBpBYC7F939QmA1cImZnQ/cBmwA3gksAf5oLipkZjeb2RYz29LT0zMXmxQR\nkQpmdB6Au/cDjwDXuPv+uJsnC/wDcEm82j5gTdnbVsdlk5Uf+xl3ufsmd9/U2TnlLCYREZml6cwC\n6jSztvh5PfBe4KW4Xx8zM+B9wAvxW+4HPhjPBroMGHD3/cBDwFVm1m5m7cBVcZmIiCyA6cwC6gLu\nMbMUITDuc/cHzOz7ZtYJGPAM8B/i9R8ErgN2AKPAhwDcvdfM/hx4Ml7vU+7eO3e7UiY7DD/9LJx9\nNazeNC8fISJyqpsyANz9OeCiCuXvmWR9B26ZZNndwN0zrOPMFcbhR38FjZ0KABGRSSTzWkAW75YX\nF7YeIiInsWQGQJQKP0sKABGRySQ0AOKeLbUAREQmlcwAsIkWQGFh6yEichJLZgAc6QIqLWw9RERO\nYskMgIkWgLqAREQmlcwAiOLd0iCwiMikkhkAEFoBagGIiEwquQEQpdQCEBGpIrkBoBaAiEhVyQ2A\nKK1ZQCIiVSQ4ACKdByAiUkVyA0BdQCIiVSU3ADQILCJSVXIDQC0AEZGqkhsAUUqDwCIiVSQ3ANQC\nEBGpKrkBEEUaAxARqSLBAZBWC0BEpIrkBoCldB6AiEgVyQ0ATQMVEakquQFgKXDNAhIRmcyUAWBm\ndWb2hJk9a2ZbzezP4vIzzOxxM9thZl8zs5q4vDZ+vSNevrZsW7fF5S+b2dXztVOABoFFRKYwnRZA\nFniPu78duBC4xswuA/4SuMPdzwL6gA/H638Y6IvL74jXw8w2AjcA5wHXAH9vNnHrrnmgaaAiIlVN\nGQAeDMcvM/HDgfcAX4/L7wHeFz+/Pn5NvPxKM7O4/F53z7r7LmAHcMmc7MUxBkbzbD80xqGhsfnY\nvIhIIkxrDMDMUmb2DNANbAZeBfrdfWKazV5gVfx8FbAHIF4+AHSUl1d4z5wquTMwXiSb1ywgEZHJ\nTCsA3L3o7hcCqwl/tW+YrwqZ2c1mtsXMtvT09MxqG6mUUcLAfY5rJyKSHDOaBeTu/cAjwOVAm5ml\n40WrgX3x833AGoB4eStwuLy8wnvKP+Mud9/k7ps6OztnUr0jMlGEY5oFJCJSxXRmAXWaWVv8vB54\nL/AiIQjeH692E/Dt+Pn98Wvi5d93d4/Lb4hnCZ0BrAeemKsdKZdOGSXXLCARkWrSU69CF3BPPGMn\nAu5z9wfMbBtwr5n9d+DnwBfj9b8I/KOZ7QB6CTN/cPetZnYfsA0oALe4z880nXQ00QWkFoCIyGSm\nDAB3fw64qEL5TirM4nH3ceDfTbKt24HbZ17NmTEzShYpAEREqkjumcAoAEREqklsALipC0hEpJrE\nBgDqAhIRqSqxAeBEGDoPQERkMokNANQFJCJSVYIDQF1AIiLVJDYA3CJMASAiMqnEBgAWgcYAREQm\nlegAUAtARGRyiQ4AjQGIiEwu0QGgaaAiIpNLcACYuoBERKpIbADoRDARkeoSGwChC0gtABGRySQ2\nANwM0y0hRUQmldgAALUARESqSWwAuGYBiYhUldgA0IlgIiLVJTYA3IxILQARkUklNgAgImJe7jkv\nIpIIiQ2AcDVQtQBERCaT7ABQF5CIyKSmDAAzW2Nmj5jZNjPbamYfi8v/1Mz2mdkz8eO6svfcZmY7\nzOxlM7u6rPyauGyHmd06P7s0ISLSNFARkUmlp7FOAfi4uz9tZs3AU2a2OV52h7v/dfnKZrYRuAE4\nD1gJfM/Mzo4X/x3wXmAv8KSZ3e/u2+ZiR94iUgtARKSaKQPA3fcD++PnQ2b2IrCqyluuB+519yyw\ny8x2AJfEy3a4+04AM7s3XndeAsB1IpiISFUzGgMws7XARcDjcdFHzew5M7vbzNrjslXAnrK37Y3L\nJis/9jNuNrMtZralp6dnJtU7ZkORpoGKiFQx7QAwsybgG8AfuPsgcCdwJnAhoYXwN3NRIXe/y903\nufumzs7O2W/ITF1AIiJVTGcMADPLEL78v+Lu3wRw94Nly78APBC/3AesKXv76riMKuVzzyJS6gIS\nEZnUdGYBGfBF4EV3/0xZeVfZar8OvBA/vx+4wcxqzewMYD3wBPAksN7MzjCzGsJA8f1zsxuVKh7v\nms4FEBGpaDotgHcBvw08b2bPxGV/DNxoZhcCDrwGfATA3bea2X2Ewd0CcIu7FwHM7KPAQ0AKuNvd\nt87hvrzZkQAogaXm7WNERE5V05kF9BPAKix6sMp7bgdur1D+YLX3zanyAEABICJyrESfCRyeaBxA\nRKSSxAZAGLpAASAiMonEBgBqAYiIVKUAEBFZpBQAIiKLlAJARGSRSmwAmE4EExGpKrEBoGmgIiLV\nJTYATAEgIlJVYgOASAEgIlJNYgPgSAugVFzYioiInKQSGwATYwDxdehEROQYiQ0Ai8IF4EoldQGJ\niFSS2AAgvhaQAkBEpLIEB0DcAiiqC0hEpJLEBsDEILCrBSAiUlFyAyCeBlrSILCISEWJDQDUAhAR\nqSrxAVAqKgBERCpJbAAcHQNQF5CISCXJDQCNAYiIVDVlAJjZGjN7xMy2mdlWM/tYXL7EzDab2fb4\nZ3tcbmb2OTPbYWbPmdnFZdu6KV5/u5ndNH+7xZFrAXlJl4MWEalkOi2AAvBxd98IXAbcYmYbgVuB\nh919PfBw/BrgWmB9/LgZuBNCYACfBC4FLgE+OREa82GiC6ikLiARkYqmDAB33+/uT8fPh4AXgVXA\n9cA98Wr3AO+Ln18PfNmDx4A2M+sCrgY2u3uvu/cBm4Fr5nRvypiuBSQiUtWMxgDMbC1wEfA4sNzd\n98eLDgDL4+ergD1lb9sbl01WPi9s4kxgdQGJiFQ07QAwsybgG8AfuPtg+TJ3d2BOvmnN7GYz22Jm\nW3p6ema/oShcC0izgEREKptWAJhZhvDl/xV3/2ZcfDDu2iH+2R2X7wPWlL19dVw2WfmbuPtd7r7J\n3Td1dnbOZF+OqXNoASgAREQqm84sIAO+CLzo7p8pW3Q/MDGT5ybg22XlH4xnA10GDMRdRQ8BV5lZ\nezz4e1VcNi9Ms4BERKpKT2OddwG/DTxvZs/EZX8MfBq4z8w+DOwGPhAvexC4DtgBjAIfAnD3XjP7\nc+DJeL1PuXvvnOxFJabzAEREqpkyANz9J4BNsvjKCus7cMsk27obuHsmFZytIy0AXQpCRKSixJ4J\nHMV3BHPdFF5EpKLEBoCZZgGJiFST2ABALQARkaoSGwBHzgTWLSFFRCpKbABEqYlLQagFICJSSWID\nAJ0IJiJSVWIDwDQGICJSVXIDQPcEFhGpKrEBEEUKABGRahIbAOoCEhGpLrkBoJvCi4hUldgA0DRQ\nEZHqEhsAR6aBKgBERCpKbABMDAKjQWARkYoSGwCaBioiUl1iAyCVUheQiEg1iQ0AJrqAFAAiIhUl\nNgAimwgATQMVEakksQEwcSJYSTeFFxGpKLEBMHEegFoAIiKVJTYATNcCEhGpKrEBEMUnguHqAhIR\nqWTKADCzu82s28xeKCv7UzPbZ2bPxI/rypbdZmY7zOxlM7u6rPyauGyHmd0697tyTL0jXQtIRKSa\n6bQAvgRcU6H8Dne/MH48CGBmG4EbgPPi9/y9maXMLAX8HXAtsBG4MV533kTRRAtAXUAiIpWkp1rB\n3X9kZmunub3rgXvdPQvsMrMdwCXxsh3uvhPAzO6N19024xpP09FBYAWAiEglxzMG8FEzey7uImqP\ny1YBe8rW2RuXTVY+byzSLCARkWpmGwB3AmcCFwL7gb+ZqwqZ2c1mtsXMtvT09Mx6O5GuBioiUtWs\nAsDdD7p70cO36xc42s2zD1hTturquGyy8krbvsvdN7n7ps7OztlUD4AolZ7Y4Ky3ISKSZLMKADPr\nKnv568DEDKH7gRvMrNbMzgDWA08ATwLrzewMM6shDBTfP/tqT+3o5aDVBSQiUsmUg8Bm9lXgCmCp\nme0FPglcYWYXAg68BnwEwN23mtl9hMHdAnCLe+iEN7OPAg8BKeBud98653tT5ui1gNQFJCJSyXRm\nAd1YofiLVda/Hbi9QvmDwIMzqt1xiKKIkhuuLiARkYqSeyZwBCVMLQARkUkkNwDM4gDQGICISCWJ\nDgAn0iwgEZFJJDYAzNQFJCJSTWID4GgXkAJARKSSxAZAKjJKRAoAEZFJJDYAIgNXC0BEZFKJDQA7\n0gWkQWARkUoSGwAQDwLrlpAiIhUlOgCcCFAAiIhUkugA0CwgEZHJJToAXLOAREQmlegAUAtARGRy\niQ4ATQMVEZlcogOgZBGmaaAiIhUlOgAcw7yw0NUQETkpJToA8qSJFAAiIhUlPAAyRKX8QldDROSk\nlOgAKFiatCsAREQqSXQAqAUgIjK5RAdAgTQptQBERCpKdADkLENKLQARkYqmDAAzu9vMus3shbKy\nJWa22cy2xz/b43Izs8+Z2Q4ze87MLi57z03x+tvN7Kb52Z03K1qGtOdOxEeJiJxyptMC+BJwzTFl\ntwIPu/t64OH4NcC1wPr4cTNwJ4TAAD4JXApcAnxyIjTmU8EymgYqIjKJKQPA3X8E9B5TfD1wT/z8\nHuB9ZeVf9uAxoM3MuoCrgc3u3uvufcBm3hoqc65oadIltQBERCqZ7RjAcnffHz8/ACyPn68C9pSt\ntzcum6x8XhWshpRaACIiFR33ILC7OzBnF9wxs5vNbIuZbenp6TmubYUxAA0Ci4hUMtsAOBh37RD/\n7I7L9wFrytZbHZdNVv4W7n6Xu29y902dnZ2zrF5QiGrIePa4tiEiklSzDYD7gYmZPDcB3y4r/2A8\nG+gyYCDuKnoIuMrM2uPB36visnk1lGqj3scgNzrfHyUicspJT7WCmX0VuAJYamZ7CbN5Pg3cZ2Yf\nBnYDH4hXfxC4DtgBjAIfAnD3XjP7c+DJeL1PufuxA8tzrj+9NDwZ2g8dZ873x4mInFKmDAB3v3GS\nRVdWWNeBWybZzt3A3TOq3XHqrVkZnrz6fQWAiMgxEn0m8M6683g283b43p9C3+6Fro6IyEkl0QGQ\nSqX5TMPHAINv/T6UigtdJRGRk0aiAyAdGQfohOv+Cnb/BH70Pxa6SiIiJ41EB0AqZRRKJXj7jbDh\nV+EHfwE//6eFrpaIyEkh0QGQiYxCycEMfuMuWHMpPPCH8NL/W+iqiYgsuEQHQCqKKBTjk5RrGuHG\ne2HFBfC134aH/gR8zk5gFhE55SQ6ANKRUSyVfck3LIEPfgvOvgYe/Vv49i0wOu+nI4iInJSSHQAT\nYwDlapvhA1+Gy34fnr0XPncRPP55nS0sIotOsgNgYgzgWKk0XPMX8JEfwpJ18C+fgM9eAI/dCQP7\n4NjQEBFJoEQHQE06Ipuv8mW+4m3wew/DB++HpefAd26FOzbCZ86FJ74A3S+duMqKiJxgU14K4lTW\nWp9hLF8kVyhRk54k66II1v0SnP4ueOHrsPm/wfABePA/h+Wd58K5vwarN8GZV4bWg4hIAiT626yt\noQaA/tEcy1rqqq+cSsPbbwiP4W7YuyUMFO/+KfS8GNbJNMKqi2HZudC+Fs65NpQvWTd/OyEiMk8S\nHgAZAPrH8lMHQLmmZbDhuvDIjcL2h2DH98L1hHpegtd+HNZ76I/DzygDpTw0d4Uw8FI48WzJOug4\nC5auD+ciiIicRBIdAB2NtQC8dGCIs5c3z24jNQ1w3q+Hx4Thbtj5A+jdCaOH4fVH4cDz4bLTQ/Gd\nMl9/9Oj6mUbI1IeAWHkhrH4nrL8KWrpmVycRkTmQ6ADYtLad9cua+JN/fp71y5o4t6tlbjbctAwu\n+MCby9yhMA75MXjmK9C4DKIUvPKd8OVfLED31nApip//Y/wmgytuhbPeG7qW1EoQkRPI/CQ+G3bT\npk2+ZcuW49rG3r5R3n/noxRKzr03X8ZZy5rmqHazlBsJrYXv/lfY++Sbl2Ua4fJboPMcOO83wgC1\niMgMmdlT7r5pyvWSHgAA2w8OceMXHiNbKPH3v3kx/2r98d1reM64Q//roVXwk89AqXB0Wcsq2Hh9\naGksf5tmH4nItCkAjrG3b5Tfu2cL27uH+fhVZ/ORXzyTVHQSdrns/GEYX9jzeJiBBNCwFM58D3Se\nHc5grmlc0CqKyMlNAVDBcLbAJ77+LA8+f4B1Sxu57bpzuXLDMqKTMQgA+l6DbfeHIHjlO0fLf+lW\nePcfQmYGM5tEZNFQAEzC3Xnw+QP89XdfZtehEdZ1NvLvLzmNX71gJStaT+Iv1MH98LP/FQaQs4Oh\nzCL4lc+E+x0oDEQkpgCYQr5Y4sHn9/MPP32NZ/b0A/C2Va388rnLufLcZZy3sgU7GWfluIfWwCO3\nh8FkgJbVsO4KWHURnP9vob59IWsoIgtMATADr/YM89DWA3xv20F+vqcfd1jRUsemte1ccc4yLj+z\ng5WtdSdfIBTz8LPPhesWTZx/AHDhb4UzmrveDnVzNPVVRE4ZJyQAzOw1YAgoAgV332RmS4CvAWuB\n14APuHufhW/PzwLXAaPA77j709W2f6ICoNyh4Szff6mbH77SwxO7eukZygKwtKmGt61q5YLVbVyw\nupXzV7XS2VR78owfDO6HL7wHht44WlbbAkvOgFWbYNPvworzF65+InLCnMgA2OTuh8rK/grodfdP\nm9mtQLu7/5GZXQf8R0IAXAp81t0vrbb9hQiAcqWSs23/ID9/vY9n9w7w3N5+tncPH7mRWHNdmnOW\nN9PVVs/K1jqWtdRx2pIG2hsyNNdl6Giqoa0+Qzp1gufzDx2E574WzjPY/dNwtjKErqHxgTCIvO4K\nWHOJTj4TSaCFDICXgSvcfb+ZdQE/cPdzzOzz8fOvHrveZNtf6ACoZCRbYOsbg7y4f5CXDw7xavcw\n+wfGOTAwTq741ktPm0F7Qw0djTV0NNWwsrWed6xt56I17axZUk9zXWb+K73zB7DjYXj5QTi842h5\n22mw8iIoFeHim8IVTxuWzH99RGRenagA2AX0AQ583t3vMrN+d2+LlxvQ5+5tZvYA8Gl3/0m87GHg\nj9x9yzHbvBm4GeC00057x+7du2ddvxOpUCzRO5rjwMA4+wfG6R3JkSuUODyS4/Bwlt6RHN1DWV47\nNMLhkRwAkcE7Tm9nw4oWutrqOLerhVVt9ZzV2TQ/XUulEuSG4fXHwsXtdv4ADm8PF6+b0LA0XJai\noSOcb/DKd2HdL0LXhbDy4jCuoJPSRE5qJyoAVrn7PjNbBmwmdPHcPxEA8Tp97t4+3QAodzK2AI6X\nu7Pr0Ahb3xjk2T39PP16H9sPDjOUPXoWcEdjDe84vZ3zV7WyflkT/3rDMuoyqfmqULj09dAbsO8p\n2PNEuOLpWN/k70nXh1trnn45YLD8fMgNQV0bnP4L4aJ3Y70wPgiFLLSuhuUbw3uLeUidgFaPyCI2\n3QA4rj/l3H1f/LPbzP4ZuAQ4aGZdZV1A3fHq+4A1ZW9fHZctKmbGus4m1nU28WtvXwmEUOgbzfPK\nwSF2HRrhydd6eXp3H5tfPIg71KQizl/VwrvPWsqV5y7nbata566FYAZr3hmeb7z+zcsKOdj+3XC5\niqZlIShe+Q7Ut8EbP4dt34ZUDWz71tSfE6XDZbMLY+H12ddCdgiWnhXurTB6OJznsP4quOi3QhCt\nfie0rjl6ldWVF4XAWn5euEqriByXWbcAzKwRiNx9KH6+GfgUcCVwuGwQeIm7f8LMfgX4KEcHgT/n\n7pdU+4wktgBmYnA8z9O7+3j01cP87NXDbH1jgJLD0qZarjinkys3LOMXz+6ksXaBumRKxXDF0+Ee\nqGsNX9Kv/Rh6d0HzCtj1Q0jVwkh3uAheuh72PAaWgtZV4f2jvaH1MFNNy8NVVgu50CXVsR7w0J3V\nfgb07Qr1wqFlZQiOjjhsDm8Pd3qLUiHYapvDdZhWXgzd20LodV0YBsprm8MVXqN0CJ1SKYSmBs/l\nJDbvXUBmtg745/hlGvg/7n67mXUA9wGnAbsJ00B74/GAvwWuIUwD/VC17h9QAByrdyTHD1/p5vsv\n9fCjV3oYGMtTk464YFUrV523nHedtZRzV7ScPFNTp6OYh7F+GOmBdC0M7AlfuMPd4X4LqZpw3wRL\nhZbG64+Fezl3rA9nRA93h1ZFsQD5kdDtVMyH517lftCzUdsSPrNlVZhBlWmIP8NCOOz6EZx2WQi1\nmsawbNnGsN7yjfDGMyG4mpaFwPRSCKWRnhBaxWzY34kusvxYCDmRGdKJYAlXKJbYsruPzdsO8uir\nh9m2P1weor0hw6a1S9jY1cKFp7Xx7rOWkjnR01AX0sS/5+wg1DRDfjT8pV/MhZYJHloG4wPQsS50\nb73wDWheGVoKfa+FL+bhg+GLe6wvdH1ZBMs2hK6qKBNaNRaFFkh24PjrnaoNAZCuC8/rWkIYRulQ\nt9Mug7Y1ISzyY2GcpXFpaKHsexre8SE48FzoNqttDkFTzIbfwVhfmN2lVsuioQBYZA4MjPPozkP8\nbMdhHt15mL19oa+9Nh2xYUUz53a1sH55M+csb+adZ7RTm56nQeXFyD08irlwa1AMel8N4xcHt4ag\n6N0JjZ3hKq8De0IL5sBzoausdU0IntZVoTVUyIZ1XvlO2Baz/D8apUNLY/RwaL10nHV0cH/1O8P1\no4YOhPGWt70/TAI45zpoOz3UuXlFCKSxvjBJYNnGMNCfqQvlDUt1z4qTlAJgkTs0nOXp3X08+Vov\nW98Y5KUDQ/TG00+ba9OcvaKZTWvb2bCimbOXN3NmZ9P8zTSSuTFyKHzxQugq2v9s+GIe7g4tnexw\naL3UtcIbT0PPy6H1c+D5ML5RKoT1LIJDr8xNndpOh5omSNeE1ysuADwE2tp/FaYan/XL0H56CIxU\nJm7BrIDBN8Lzzg2hdZOuC0HZsETXszpOCgB5i0PDWX726mF+/EoP27uH2frGAPliOP6RwekdjaxZ\n0kBHYw0bVjTT0VTLipY6murStNSlWbOkYXF1JyVdMR9mYqUyITzG+0NLZrwfcqNhKu9obzh3pHdn\nOLN82bkhULJDYVxm1cWhxTK4LwQOHgJofBbdYnVt4bMhzPgq5kNYZerh8KthXGXNJXD6u0IY5kfg\nnF8JLZT8CJx5Zei2m5gMYKkwQaBYePO5K+6J7w5TAMiU8sUSrx0a4aUDQ2zvHmZH9xB7esfoHhrn\n4GD2LevXpCNWt9WzrKWWjqZa1i1tpL2hhuUtdbQ1ZGitD4/xfJHV7Q3U16hFsahMfJeYhS/vwztC\nGOTHwiyw8f7wV/9wd7h/dnMXeBF+/Ddh+m//62EGVpQOg+KlQpjNNROWCtucTEPH0UujnPXe0BXW\neU7onnv+vvD+jddD/+4QNOm60BqZmHY8ciiMvZzkFAByXIbG8/SO5NjXP0bfSJ6xfJFXDg6xr3+M\nAwPjHBrO8nrvKNX++dRlItJRRG06oqOphtOWNJIvluhorGFlWz0NtSlq0ylq0hF16Yj2hhrSKWN5\nSx3NdekjrQ0DWuoz6qJajMpDZbg7dCMdeDZcAn2kGw5tDy2EsX7Y/0wY04hSoVUyMe6y85Gj26tv\nr36S42QyDaHbbbwflpwJZ/xi+KyWrtBKKebgjF8K4dXYGS7CWNsSPttLYf38eFgfwnTieRw/UQDI\nvBvPFxnJFjg0nKN/NEf/WJ6BsTwA+/rGGBjL4+4MjhfoH81xIG5VDIzmODA4TmmG//Q6m2tJmdFU\nlz4SEAa0NWRIRUapBI5zxtImmmpTpFMR6cioy6TIFko016Vprc/QUJMiXyxRn0nTVJsmnTIy8bqZ\ndMSBgTHO7WqhPpM6cglwdz/5Lgcux6dYCK2Bvl2hZTJx9dztm8M5Lf27w/hGlIKBvWFm2MQ9OGZr\n1aYQXP2vh3NSlm2E1x8NXVnLNoRzY0Z6Qqh1bgiD87NwQs4ElsWtLpOiLpOio6l2xu91d8bzJXKF\nEtlikbFckUPDISC6B7MMjRcolBzHyRdKR66lVHJnOFtgaLzAeL5IvuTs7BnBCV1ahaLzvRe7Kc40\nXSruX3QkGIazBRpq0ixrrqUY/9G0tKmWiUhY3lJHOmU01abpH80TGXQ01bKmvZ50KsIMMqmITMpI\nRxHFkrO8pY7G2hSRGbliiWXNtTTVpqlNp6hNR6fW+RynolQampeHR7mOM6d+r8fjDMPd4a9/sxAi\nB7eG8okv8uwQDB8IrZHcSAgTCC2FvtfCA+CZf3rrZ5x2OZz3G/PaUlAAyIIwM+prUvE4QTjx6fSO\nubnZvbuTLzrFkpMvlRgeL1CfSTGcLTAwlmc0VySTMgbHC4zlimQLoc84my8xXihyeDhHOjL6RvMh\ngIolSg7pyOgezDKWL1KXiegdyTGSK+IO+wf6GcsXyRVKDIyFADjeDEpHRn0mRUt9aOFEFsZhIjNO\n72g40kIZGi+wrKWWunSKptoFPi0ZAAAIG0lEQVQUdTUp6jPhUZcJrZ2adERzXZqWugwOdLXWkYqM\nXKHEaK7Ius5GalKRWjnTZRbGCya6dCBcXfe0y2a2Hfcw0J6uCWMlQwdCF9XAXjjn2nmfZqsAkMQx\nM2rS4YusnhQt8SW32xtr3nQxqvlUKjkO9I/mKLrjHloo+aJTKJYolJzDwzlGcwVKcfdS70iOsVyR\nXLHEWK5Ivhi+nAfH85RKTskhWygyli+x+/AoY/kiI9kiLfVpHt95GAdGcoWq4zJTqUlH1KYiajMR\nDTVpGuKQHssVqa9JUXIYHs+zqr2BXKHIaUsaaK7LkEmFsR53p72xhnRkmBl7+8Y4s7ORlW31ZAtF\nGmvSRJFRKjmNtWmGxgucsbSRkofA7myuZWi8ELeE3toKSlxXnBk0doTntc3hLPETSAEgMg8mvrhm\n0z12PEolD91jhSJD4wXcne6hLJEZ7k6hFL5o9w+MM5oLV6DdfnCY0zoayBZKZAtFsvnQ5eaEcZ6x\nXJGm2jSFohNF8NL+wSP3vth+cJhsIXTlVbofxvGoSUWkIqO9IcNwtsDgeIHGmhRnr2imLp0ik46o\nSVkIeIPI7Eg323i+SO9Ijl84cynFkmMGXa31FEolMqmIujjgsoUSTbWp0IUXRXELKxy/lhNxr44F\npgAQSZAoMlobMrSSYXl8O+j1y5tPyGeXSk7RncGxPMWSM5orEpkxmi/QO5I70g2XzZcwg5FckeHx\nAo6TjoxCyTk4mKWhJsXAWJ7BsTz1mRS9ozkGx/Kko4iDQ+NhEL/gjI3lGcsV6RsdIJMK4yrjhbDN\nQtz/9r0Xu6eodWVm4Sz6UglWt9dTdKexJs2SxhryxRIvHxxiY1cLdXFXWyoyGmtTdDbX0ViTorku\nQ+9INkydbm+gUAotv9M7GjgwkGVFa11o4Zixsq2OmnR0pEtvNFegLp06IWNACgARmRNRZETYCW/1\nVFIqOf3xjLRMyuKgyJMtFCl5mFo8OJ4nFRmDY2GWmgPZfOiCGx4vMF4oMTiWp280R7ZQCq2hfJFC\nyRnPFzk4OI6ZMTCWp380R2NtOp75Nrs616QjmmrT9I7kaKxJcdm6Dr74O++cs99JJQoAEUmcKDKW\nNNYced1cl2FZS928fd7E2ES+WGI0W2QkVzjSZTZxd8BUNBEWeYazBRprUxwezoXLSLnTN5pjaLzA\nrp4ROppqOLerZd7qO0EBICJynCYGpjOpiNaGiNaGo+MHq9tP3psX6cIuIiKLlAJARGSRUgCIiCxS\nCgARkUVKASAiskgpAEREFikFgIjIIqUAEBFZpE7qG8KYWQ+w+zg2sRQ4NEfVOVVonxcH7fPiMNt9\nPt3dO6da6aQOgONlZlumc1ecJNE+Lw7a58VhvvdZXUAiIouUAkBEZJFKegDctdAVWADa58VB+7w4\nzOs+J3oMQEREJpf0FoCIiEwikQFgZteY2ctmtsPMbl3o+swVM1tjZo+Y2TYz22pmH4vLl5jZZjPb\nHv9sj8vNzD4X/x6eM7OLF3YPZs/MUmb2czN7IH59hpk9Hu/b18ysJi6vjV/viJevXch6z5aZtZnZ\n183sJTN70cwuT/pxNrM/jP9dv2BmXzWzuqQdZzO728y6zeyFsrIZH1czuylef7uZ3TTb+iQuAMws\nBfwdcC2wEbjRzDYubK3mTAH4uLtvBC4Dbon37VbgYXdfDzwcv4bwO1gfP24G7jzxVZ4zHwNeLHv9\nl8Ad7n4W0Ad8OC7/MNAXl98Rr3cq+izwHXffALydsO+JPc5mtgr4T8Amdz8fSAE3kLzj/CXgmmPK\nZnRczWwJ8EngUuAS4JMToTFj7p6oB3A58FDZ69uA2xa6XvO0r98G3gu8DHTFZV3Ay/HzzwM3lq1/\nZL1T6QGsjv9jvAd4gHBL10NA+thjDjwEXB4/T8fr2ULvwwz3txXYdWy9k3ycgVXAHmBJfNweAK5O\n4nEG1gIvzPa4AjcCny8rf9N6M3kkrgXA0X9IE/bGZYkSN3kvAh4Hlrv7/njRAWB5/Dwpv4v/CXwC\nKMWvO4B+dy/Er8v368g+x8sH4vVPJWcAPcA/xN1e/9vMGknwcXb3fcBfA68D+wnH7SmSfZwnzPS4\nztnxTmIAJJ6ZNQHfAP7A3QfLl3n4kyAxU7vM7FeBbnd/aqHrcgKlgYuBO939ImCEo90CQCKPcztw\nPSH8VgKNvLWrJPFO9HFNYgDsA9aUvV4dlyWCmWUIX/5fcfdvxsUHzawrXt4FdMflSfhdvAv4N2b2\nGnAvoRvos0CbmaXjdcr368g+x8tbgcMnssJzYC+w190fj19/nRAIST7Ovwzscvced88D3yQc+yQf\n5wkzPa5zdryTGABPAuvj2QM1hIGk+xe4TnPCzAz4IvCiu3+mbNH9wMRMgJsIYwMT5R+MZxNcBgyU\nNTVPCe5+m7uvdve1hGP5fXf/TeAR4P3xasfu88Tv4v3x+qfUX8rufgDYY2bnxEVXAttI8HEmdP1c\nZmYN8b/ziX1O7HEuM9Pj+hBwlZm1xy2nq+KymVvoAZF5GmS5DngFeBX4k4Wuzxzu17sJzcPngGfi\nx3WEvs+Hge3A94Al8fpGmBH1KvA8YYbFgu/Hcez/FcAD8fN1wBPADuD/ArVxeV38eke8fN1C13uW\n+3ohsCU+1t8C2pN+nIE/A14CXgD+EahN2nEGvkoY48gTWnofns1xBX433vcdwIdmWx+dCSwiskgl\nsQtIRESmQQEgIrJIKQBERBYpBYCIyCKlABARWaQUACIii5QCQERkkVIAiIgsUv8fACSrQbb5NfUA\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgk-FbQtEe-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predicted = model.predict([x_test_t])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLZ0IK2ZG4Sw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(np.shape(y_test_t))\n",
        "##print(np.shape(predicted))\n",
        "\n",
        "actual =[]\n",
        "pred=[]\n",
        "se=0\n",
        "show = np.hstack((y_test_t, predicted))\n",
        "\n",
        "for i in show:\n",
        "  se+=(i[0]-i[1])**2\n",
        "  actual.append(i[0])\n",
        "  pred.append(i[1])\n",
        "  \n",
        " \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILK9hZaGIxjK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse = (se/np.size(y_test_t))**0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd0E9kjt5gq3",
        "colab_type": "code",
        "outputId": "7fe71b43-bcb6-496a-b2f0-f1da77c9ce42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(rmse)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15.423726140156969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EF-jVYmG4URr",
        "colab_type": "code",
        "outputId": "5ea65909-5b35-4a8d-ee52-174ef7a3b10e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(actual)\n",
        "plt.plot(pred)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf14b64d68>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBxVOdCsw57E",
        "colab_type": "code",
        "outputId": "07050a66-65b7-447e-9e25-e1da45e10bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.shape(labels))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2376, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3wca5LoCfEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8zj52CuhmPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = tf.placeholder(shape = (None,9), dtype = tf.float32, name = 'input' )\n",
        "y = tf.placeholder(shape = (None,1), dtype = tf.float32, name = 'target')\n",
        "\n",
        "#Layer 1 \n",
        "w1 = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((9, 15)))\n",
        "b1 = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((1,15)))\n",
        "\n",
        "#Layer2 \n",
        "\n",
        "w2 = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((15,25)))\n",
        "b2 = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((1,25)))\n",
        "\n",
        "#out\n",
        "\n",
        "wo = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((25,1)))\n",
        "bo = tf.Variable(tf.glorot_uniform_initializer(dtype = tf.float32)((1,1)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92_mLSDYpmcv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hidl1 = tf.add(tf.matmul(x,w1),b1, name ='hidden1')\n",
        "hidl1 = tf.nn.relu(hidl1)\n",
        "hidl2 = tf.add(tf.matmul(hidl1,w2),b2, name = 'hidden2')\n",
        "hidl2 = tf.nn.relu(hidl2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYnF_9OusKXw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#outl_batch = tf.compat.v1.layers.batch_normalization(hidl2)\n",
        "out = tf.add(tf.matmul(hidl2,wo),bo,name = 'output')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OdDRQggsq5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss = tf.reduce_mean(tf.square(tf.subtract(y,out))) \n",
        "\n",
        "opt = tf.train.AdamOptimizer(name = 'optimizer')\n",
        "op_train = opt.minimize(loss, name ='train_op')\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiyIZ5_FvMjz",
        "colab_type": "text"
      },
      "source": [
        "Add additional custom loss functions if necc \n",
        "reducing mean sqaure error \n",
        "1. reducing max deviation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgbtgE_CvDzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "saved = tf.train.Saver().as_saver_def()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLnEbChLyH82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nh28JgrUxRjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train=[]\n",
        "val=[]\n",
        "\n",
        "with tf.device('/device:CPU:0'):\n",
        "  update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "  save = tf.train.Saver()\n",
        "  with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    mini =[]\n",
        "    for i in range(1500):\n",
        "      b1=[]\n",
        "      b2=[]\n",
        "      l1=[]\n",
        "      l2=[]\n",
        "      b1_val=[]\n",
        "      b2_val=[]\n",
        "      l1_val=[]\n",
        "      l2_val=[]\n",
        "      x_traint, x_test_t,y_traint, y_test_t = train_test_split(features, labels, test_size = 0.3)\n",
        "      x_trainv, x_testv, y_trainv, y_testv = train_test_split(x_traint, y_traint, test_size = 0.3)\n",
        "      \n",
        "      for j in range(16): ##One run is appending 2 random lists \n",
        "      \n",
        "      #TRAINING MINI BATCHES \n",
        "        \n",
        "        seed = random.choice(range(len(x_trainv)))\n",
        "        i = random.choice(range(len(x_trainv)))\n",
        "        \n",
        "        b1.append(x_trainv[seed])\n",
        "        b2.append(x_trainv[i])\n",
        "        l1.append(y_trainv[seed])\n",
        "        l2.append(y_trainv[i])\n",
        "        \n",
        "        x_batch = np.vstack((b1,b2))\n",
        "        y_batch = np.vstack((l1,l2))\n",
        "        \n",
        "        ##VALIDATION MINI BATCHES \n",
        "        \n",
        "        seed_val = random.choice(range(len(x_traint)))\n",
        "        i_val = random.choice(range(len(x_traint)))\n",
        "        \n",
        "        b1_val.append(x_traint[seed_val])\n",
        "        b2_val.append(x_traint[i_val])\n",
        "        l1_val.append(y_traint[seed_val])\n",
        "        l2_val.append(y_traint[i_val])\n",
        "        \n",
        "        x_batch_val = np.vstack((b1_val,b2_val))\n",
        "        y_batch_val = np.vstack((l1_val,l2_val))\n",
        "      \n",
        "      ## TRAINING LOSS\n",
        "      update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
        "      z= sess.run([loss,op_train, update_ops], feed_dict = {x : x_batch, y: y_batch })\n",
        "      train.append(z[0])\n",
        "      \n",
        "      ##VALIDATION LOSS\n",
        "      \n",
        "      z_val= sess.run([loss], feed_dict = {x : x_batch_val, y: y_batch_val })\n",
        "      val.append(z_val[0])\n",
        "      \n",
        "      print(str(z[0]) + '\\t' + str(z_val[0]))\n",
        "    \n",
        "    plt.plot(train)\n",
        "    plt.plot(val)\n",
        "    save_path = save.save(sess, \"/content/layer2_model.ckpt\")\n",
        "    print('Saved model!')\n",
        "    \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_x4rrbw8Z6Pw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "665f803c-b22b-4ed3-b989-6ae3ec347327"
      },
      "source": [
        "print(z)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[705.08997, None, []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6Jpi8Pe_wxr",
        "colab_type": "code",
        "outputId": "4f773c6b-acfa-41da-d55b-6e7e8aceb8b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(type(tf.get_default_graph().as_graph_def()))\n",
        "tf.io.write_graph(tf.get_default_graph().as_graph_def(), '/content/', 'layer2_train.pbtxt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.core.framework.graph_pb2.GraphDef'>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/final_train.pbtxt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOCKeDcHDKe7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/final_graph.pb', 'wb') as f:\n",
        "  f.write(tf.get_default_graph().as_graph_def().SerializeToString())\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orqHTKay9Mxd",
        "colab_type": "code",
        "outputId": "f14ab957-d9a4-47be-9305-a92edc693e20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "plt.plot(train[1:])\n",
        "plt.plot(val[1:])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fcf4048c908>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlP8H9q9JRvbvAbAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gD0khtg3KTgJ",
        "colab_type": "code",
        "outputId": "d500ad6a-fe46-40ae-dcff-84990f23080f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        }
      },
      "source": [
        "tf.trainable_variables()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<tf.Variable 'Variable:0' shape=(9, 15) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_1:0' shape=(1, 15) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_2:0' shape=(15, 1) dtype=float32_ref>,\n",
              " <tf.Variable 'Variable_3:0' shape=(1, 1) dtype=float32_ref>,\n",
              " <tf.Variable 'batch_normalization/gamma:0' shape=(15,) dtype=float32_ref>,\n",
              " <tf.Variable 'batch_normalization/beta:0' shape=(15,) dtype=float32_ref>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nya53qsuBwmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "zN5cGlK9ZSOD",
        "colab": {}
      },
      "source": [
        "## 48 BIT (2253,2315)\n",
        "'''\n",
        "features = joblib.load('/content/features48.pkl')\n",
        "labels = joblib.load('/content/labels48.pkl')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ2cpkrT1ypE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 16 BIT (2253,267)\n",
        "'''\n",
        "features = joblib.load('/content/features16.pkl')\n",
        "labels = joblib.load('/content/labels16.pkl')\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZObnZaVoftWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}