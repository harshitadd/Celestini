{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AirQuality and Delhi NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshitadd/Celestini/blob/master/AirQuality_and_Delhi_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nALvuXWQtEE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlRTxtY2UDfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install firebase-admin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5Hu0PvB22iD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Get Images from Firebase Storage\n",
        "import datetime\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials\n",
        "from firebase_admin import storage\n",
        "\n",
        "# Fetch the service account key JSON file contents\n",
        "cred = credentials.Certificate(\"credentials.json\")\n",
        "\n",
        "# Initialize the app with a service account, granting admin privileges\n",
        "app = firebase_admin.initialize_app(cred, {\n",
        "    'storageBucket': 'fir-4ca2c.appspot.com',\n",
        "}, name='storage')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y09fw1mQYG-K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def getImgName(name):\n",
        "  try:\n",
        "    return (name.split('/')[2].split(':')[0]  + \":\" + name.split('/')[2].split(':')[1])\n",
        "  except:\n",
        "    print(\"Not a valid image name\")\n",
        "\n",
        "def getReading(string):\n",
        "  try:\n",
        "    return(string[0].split(':')[0] + \":\" + string[0].split(':')[1])\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FtlK4Snect4J",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "data = []\n",
        "reading = []\n",
        "# t = 0\n",
        "bucket = storage.bucket(app=app)\n",
        "blobs = bucket.list_blobs()\n",
        "# for blob in blobs:\n",
        "#   t +=1\n",
        "# print(t)\n",
        "\n",
        "\n",
        "mits = set()\n",
        "for blob in blobs:\n",
        "    with open('airveda1.csv') as csv_file:\n",
        "      csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "      for row in csv_reader:\n",
        "        reading = []\n",
        "        if(getReading(row) == getImgName(blob.name) and getReading(row) not in mits):\n",
        "          mits.add(getImgName(blob.name))\n",
        "          blob.download_to_filename('/content/' + str(blob.name.split('/')[-1])+ '.jpeg')\n",
        "          print(getReading(row))\n",
        "          img = cv2.imread(str(blob.name.split('/')[-1])+ '.jpeg')\n",
        "          img = cv2.resize(img,(16, 16))\n",
        "          x = []\n",
        "          x.append(np.array(img))\n",
        "          x.append(row[1])\n",
        "          x.append(row[2])\n",
        "          x.append(row[3])\n",
        "          reading.append(np.array(x))\n",
        "          data.append(np.array(reading)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryrtPTy8DjaC",
        "colab_type": "code",
        "outputId": "4f6fc51e-46d3-4831-d76d-3ada818d4598",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(np.shape(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(255, 1, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjTFIZiCeHNA",
        "colab_type": "code",
        "outputId": "d94d8581-1928-4efe-b06b-1f3c8f1df352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = np.array(data)\n",
        "data = np.squeeze(data, axis = 1)\n",
        "print(data.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(255, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1BHKyHp0yea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def transmission(img, lt = 230, retMean = False):\n",
        "  ker = np.ones((3, 3))/9.0\n",
        "  imgrgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  b, g, r = cv2.split(img)\n",
        "  hsv = cv2.cvtColor(imgrgb, cv2.COLOR_RGB2HSV)\n",
        "  _, _, v = cv2.split(hsv)\n",
        "  v_blur = cv2.filter2D(v, -1, ker)\n",
        "  _,building_mask = cv2.threshold(v_blur, lt, 255, cv2.THRESH_BINARY)\n",
        "  sky = cv2.bitwise_and(imgrgb, imgrgb, mask = building_mask)\n",
        "  sky_mask = cv2.bitwise_not(building_mask, building_mask.copy())\n",
        "  building = cv2.bitwise_and(imgrgb, imgrgb, mask = sky_mask)\n",
        "  #f, ax = plt.subplots(2, 1, figsize = (15, 15))\n",
        "  #ax[0].imshow(imgrgb)\n",
        "  #ax[1].imshow(sky)\n",
        "  #ax[2].imshow(building)\n",
        "  al = max(v_blur.flatten())\n",
        "  #Airlight Found. Now calculate Transmission Map\"\n",
        "  img_norm = img/float(al)\n",
        "  b, g, r = cv2.split(img_norm)\n",
        "  kernel = np.ones((3,3),np.uint8)\n",
        "  im_new = np.zeros((img.shape[0], img.shape[1]))\n",
        "  for i in range(img.shape[0]):\n",
        "    for j in range(img.shape[1]):\n",
        "      im_new[i][j] = min(b[i][j], g[i][j], r[i][j])\n",
        "  dcp = cv2.erode(im_new, kernel, iterations = 1)\n",
        "  #ax[3].imshow(im_new, cmap = 'gray')\n",
        "  #ax[4].imshow(dcp, cmap = 'gray')\n",
        "  tr = np.ones((dcp.shape[0], dcp.shape[1]))\n",
        "  for i in range(dcp.shape[0]):\n",
        "    for j in range(dcp.shape[1]):\n",
        "      tr[i][j] = 1 - dcp[i][j]\n",
        "  #ax[1].imshow(tr, cmap = 'gray')\n",
        "  if retMean == False:\n",
        "    return tr\n",
        "  elif retMean == True:\n",
        "    return np.mean(tr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7FCyCW_d-ZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def contrast(image):\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  s = 0\n",
        "  ss = 0\n",
        "  mean = np.mean(image)\n",
        "  x = (-1 * mean * (np.ones(image.shape)))\n",
        "  ss = np.square(np.add(image, x))\n",
        "  cont = np.sqrt(np.sum(ss)/float(image.size))\n",
        "  return cont"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVEPKBa1hrBc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "def entropy(image):\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  hist = cv2.calcHist( [image.astype('float32')],\n",
        "              [0], \n",
        "              None,\n",
        "               [256], \n",
        "              [0,256] )\n",
        "  h_norm = 0\n",
        "  h_norm = cv2.normalize(hist, h_norm)\n",
        "  ent = 0\n",
        "  for p in h_norm:\n",
        "    try:\n",
        "      ent += p*math.log(p, 2)\n",
        "    except:\n",
        "      pass\n",
        "  return (-1 * ent[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8tc2snQF7th",
        "colab_type": "code",
        "outputId": "4b4583a3-b686-468a-8374-ad5ab331094c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# Run this cell to mount your Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92w4jnUrF3VI",
        "colab_type": "code",
        "outputId": "233be8ad-be3a-474e-ec82-0561f2c24b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "!unzip drive/My\\ Drive/croppedimg.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/My Drive/croppedimg.zip\n",
            "replace 201405071100.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3q5iEdTFPz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx2Rwf0yW3Pg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def createFeatureVector(data, m = 'nn', retMean = False):\n",
        "  features = []\n",
        "  features_img = []\n",
        "  features_oth = []\n",
        "  ctr = 0\n",
        "  for i in range(data.shape[0]):\n",
        "    img = data[i][0]\n",
        "    tr = transmission(img, retMean)\n",
        "    #print(min(tr.flatten()), max(tr.flatten()))\n",
        "    if m == 'nn':\n",
        "      tr = np.reshape(tr, (16, 16, 1))\n",
        "      features_img.append(tr)\n",
        "      ent = entropy(img)\n",
        "      cont = contrast(img)\n",
        "      features_oth.append([ent, cont])\n",
        "      ctr += 1\n",
        "    elif m == 'ml':\n",
        "      features.append(np.hstack((tr.flatten(), entropy(img), contrast(img))))\n",
        "      ctr += 1\n",
        "    print(ctr)\n",
        "  s1 = MinMaxScaler()\n",
        "  s2 = MinMaxScaler()\n",
        "  \n",
        "  features_oth = np.array(features_oth)\n",
        "  #print(features_oth)\n",
        "  #print(features_oth[:, 0])\n",
        "  features_oth[1] = np.array(features_oth[1])\n",
        "  z1 = s1.fit_transform(features_oth[:, 0].reshape(-1, 1))\n",
        "  print(z1.shape)\n",
        "  z2 = s2.fit_transform(features_oth[:, 1].reshape(-1, 1))\n",
        "  print(z2.shape)\n",
        "  z = np.hstack((z1, z2))\n",
        "  #print(z)\n",
        "  if m == 'nn':\n",
        "    return features_img, z\n",
        "  elif m == 'ml':\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBnHM2XUhYTs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def genLabels(data):\n",
        "  labels = []\n",
        "  for i in range(data.shape[0]):\n",
        "    #x = []\n",
        "    #x.append(data[i][1])\n",
        "    #x.append(data[i][3])   \n",
        "    labels.append(float(data[i][2]))\n",
        "  return labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HqYxJVcXXJcX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = createFeatureVector(data, 'nn')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uWR2plqKe5n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = genLabels(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujDlbJZfOFoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(features[0]))\n",
        "img_feat = features[0]\n",
        "oth_feat = features[1]\n",
        "print(np.shape(img_feat))\n",
        "print(oth_feat.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpy-386FX4YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(oth_feat)\n",
        "# print(oth_feat[:, 0])\n",
        "print('Entropy Mean: ', np.mean(oth_feat[:, 0]))\n",
        "print('Entropy Variance: ', np.var(oth_feat[:, 0]))\n",
        "print('Contrast Mean: ', np.mean(oth_feat[:, 1]))\n",
        "print('Contrast Variance: ', np.var(oth_feat[:, 1]))\n",
        "print('Transmission Mean: ', np.mean(img_feat))\n",
        "print('Transmission Variance: ', np.var(img_feat))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pbIzCy7vcy5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "####################################################################################################################################################\n",
        "############################################################# DELHI DATASET NEURAL NETWORK #########################################################\n",
        "####################################################################################################################################################\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, Flatten, Conv2D, Input, BatchNormalization, Concatenate, Dropout, LeakyReLU\n",
        "model = 0\n",
        "\n",
        "\n",
        "#Input Layers\n",
        "inp_img = Input(shape=(16, 16, 1, ), dtype='float32', name = 'img_inp')\n",
        "inp_oth = Input(shape = (2, ), dtype = 'float32', name = 'oth_inp')\n",
        "\n",
        "#1st Conv + Dropout + BatchNorm\n",
        "conv1 = Conv2D(8, kernel_size = 3, strides = 2, name = 'conv1', padding = 'same')(inp_img)\n",
        "relu1 = LeakyReLU(alpha = 0.01)(conv1)\n",
        "# batch_norm1 = BatchNormalization(name = 'batch1', axis = -1, momentum = 0.05)(relu1)\n",
        "drop1 = Dropout(rate = 0.7, name = 'drop1')(relu1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#2nd Conv + Dropout + BatchNorm\n",
        "conv2 = Conv2D(5, kernel_size = 3, strides = 2, name = 'conv2', padding = 'same')(drop1)#batch_norm1\n",
        "relu2 = LeakyReLU(alpha = 0.01)(conv2)\n",
        "# batch_norm2 = BatchNormalization(name = 'batch2', axis = -1, momentum = 0.05)(relu2)\n",
        "drop2 = Dropout(rate = 0.7, name = 'drop2')(relu2)\n",
        "\n",
        "\n",
        "\n",
        "#Flatten Convolution Maps\n",
        "flat = Flatten(name = 'flatConv')(drop2)#drop3\n",
        "\n",
        "\n",
        "\n",
        "#---------------------------------------------------------------------------------------------------------------\n",
        "#Send in Entropy and Contrast\n",
        "dense1 = Dense(10, activation = 'relu', name = 'Dense1')(inp_oth)\n",
        "dropd2 = Dropout(rate = 0.5, name = 'dropd2')(dense1)\n",
        "\n",
        "#------------------------------------------------------------------------------------------------------------------\n",
        "#Join CNN and DNN\n",
        "join = Concatenate()([flat, dropd2])#drop4\n",
        "dropJoin = Dropout(rate = 0.5, name = 'dropJoin')(join)\n",
        "\n",
        "\n",
        "#Add Dense Layer on Top\n",
        "dense3 = Dense(10, activation='relu', name = 'Dense3')(dropJoin)\n",
        "dense4 = Dense(5, activation='relu', name = 'Dense3')(dense3)\n",
        "\n",
        "drop7 = Dropout(rate = 0.5, name = 'drop7')(dense4)\n",
        "\n",
        "\n",
        "\n",
        "#Output Layer\n",
        "output = Dense(1, name = 'output')(dense3)#batch_norm5\n",
        "\n",
        "model = Model(inputs=[inp_img, inp_oth], outputs=[output])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAFrvurpJLfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Adadelta, Adam, SGD, RMSprop, Nadam\n",
        "model.compile(optimizer= Nadam(lr = 0.0001), loss= 'mse')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-mkg1rQvV8G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit([img_feat, oth_feat], labels, epochs = 2000, batch_size = 32, validation_split = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qjP7WnjvaW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
        "ax.plot(hist.history['loss'])\n",
        "ax.plot(hist.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4s13AWn5rP5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('newModel182_910_data.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OVXxKRaXnHl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "layer_outputs = [layer.output for layer in model.layers[1:3]] # Extracts the outputs of the top 12 layers\n",
        "activation_model = Model(inputs=model.input, outputs=layer_outputs) # Creates a model that will return these outputs, given the model input"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M78FMJaJXz5l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install git+git://github.com/raghakot/keras-vis.git --upgrade --no-deps\n",
        "activations = activation_model.predict([img_feat, oth_feat])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gp4cYFwvhb_6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(np.shape(activations[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_NH0Cyxhtrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(img_feat[20].shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESTtm6gnbtr-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "first_layer_activation = activations[0][17]\n",
        "plt.imshow(img_feat[17].reshape((32, 32)), cmap = 'gray')\n",
        "print(first_layer_activation.shape)\n",
        "f, ax = plt.subplots(4, 4, figsize = (10, 10))\n",
        "for i in range(16):\n",
        "  j = int((i)/4)\n",
        "  x = int(i%4)\n",
        "  ax[j][x].matshow(first_layer_activation[:, :, i], cmap='viridis')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PTxMa7OdDKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#model.save(\"model_231_198.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZAYG4Nkn5gU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model_s = load_model('model_341_411.hdf5')\n",
        "#model_s.layers.remove()\n",
        "model_s.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KzJhNuCoPai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dF_OqbqKeiyE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_s.save_weights('w.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_ZMeDUJoKIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist_s = model_s.fit([img_feat, oth_feat], labels, epochs = 3000, batch_size = 32, validation_split = 0.3, shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sj-1OftusARX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_s.save(\"model_s_231_200.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v1rfy9MZoZ1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f, ax = plt.subplots(1, 1, figsize = (6, 6))\n",
        "ax.plot(hist_s.history['loss'])\n",
        "ax.plot(hist_s.history['val_loss'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B89Q7LmIenPd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = model.predict([img_test, oth_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgDzLa-liFp9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error\n",
        "print(r2_score(pred, labels_test))\n",
        "print(mean_absolute_error(pred, labels_test))\n",
        "rmse = (mean_squared_error(pred, labels_test))**0.5\n",
        "print(rmse)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}